2025-10-09 18:23:48,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 18:23:48,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 18:23:48,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 18:23:48,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 18:24:04,326:INFO:PyCaret RegressionExperiment
2025-10-09 18:24:04,327:INFO:Logging name: reg-default-name
2025-10-09 18:24:04,327:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-09 18:24:04,327:INFO:version 3.3.2
2025-10-09 18:24:04,327:INFO:Initializing setup()
2025-10-09 18:24:04,327:INFO:self.USI: 77b4
2025-10-09 18:24:04,327:INFO:self._variable_keys: {'X', 'seed', 'log_plots_param', 'X_test', 'memory', 'gpu_param', 'target_param', '_ml_usecase', 'USI', 'data', 'y_train', 'exp_name_log', 'n_jobs_param', 'idx', 'y', 'exp_id', 'fold_shuffle_param', 'fold_groups_param', 'gpu_n_jobs_param', 'y_test', 'fold_generator', 'X_train', 'transform_target_param', 'pipeline', 'html_param', 'logging_param', '_available_plots'}
2025-10-09 18:24:04,327:INFO:Checking environment
2025-10-09 18:24:04,327:INFO:python_version: 3.10.0
2025-10-09 18:24:04,327:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-10-09 18:24:04,327:INFO:machine: AMD64
2025-10-09 18:24:04,327:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-09 18:24:04,328:INFO:Memory: svmem(total=17042837504, available=6094282752, percent=64.2, used=10948554752, free=6094282752)
2025-10-09 18:24:04,328:INFO:Physical Core: 6
2025-10-09 18:24:04,328:INFO:Logical Core: 12
2025-10-09 18:24:04,328:INFO:Checking libraries
2025-10-09 18:24:04,328:INFO:System:
2025-10-09 18:24:04,328:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-10-09 18:24:04,328:INFO:executable: c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\python.exe
2025-10-09 18:24:04,328:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-09 18:24:04,328:INFO:PyCaret required dependencies:
2025-10-09 18:24:04,404:INFO:                 pip: 25.2
2025-10-09 18:24:04,404:INFO:          setuptools: 80.9.0
2025-10-09 18:24:04,404:INFO:             pycaret: 3.3.2
2025-10-09 18:24:04,404:INFO:             IPython: 8.37.0
2025-10-09 18:24:04,404:INFO:          ipywidgets: 8.1.7
2025-10-09 18:24:04,404:INFO:                tqdm: 4.67.1
2025-10-09 18:24:04,404:INFO:               numpy: 1.26.4
2025-10-09 18:24:04,404:INFO:              pandas: 2.1.4
2025-10-09 18:24:04,404:INFO:              jinja2: 3.1.6
2025-10-09 18:24:04,404:INFO:               scipy: 1.11.4
2025-10-09 18:24:04,404:INFO:              joblib: 1.3.2
2025-10-09 18:24:04,404:INFO:             sklearn: 1.4.2
2025-10-09 18:24:04,404:INFO:                pyod: 2.0.5
2025-10-09 18:24:04,404:INFO:            imblearn: 0.14.0
2025-10-09 18:24:04,404:INFO:   category_encoders: 2.7.0
2025-10-09 18:24:04,404:INFO:            lightgbm: 4.6.0
2025-10-09 18:24:04,404:INFO:               numba: 0.62.1
2025-10-09 18:24:04,404:INFO:            requests: 2.32.5
2025-10-09 18:24:04,404:INFO:          matplotlib: 3.7.5
2025-10-09 18:24:04,404:INFO:          scikitplot: 0.3.7
2025-10-09 18:24:04,404:INFO:         yellowbrick: 1.5
2025-10-09 18:24:04,405:INFO:              plotly: 6.3.1
2025-10-09 18:24:04,405:INFO:    plotly-resampler: Not installed
2025-10-09 18:24:04,405:INFO:             kaleido: 1.1.0
2025-10-09 18:24:04,405:INFO:           schemdraw: 0.15
2025-10-09 18:24:04,405:INFO:         statsmodels: 0.14.5
2025-10-09 18:24:04,405:INFO:              sktime: 0.26.0
2025-10-09 18:24:04,405:INFO:               tbats: 1.1.3
2025-10-09 18:24:04,405:INFO:            pmdarima: 2.0.4
2025-10-09 18:24:04,405:INFO:              psutil: 7.1.0
2025-10-09 18:24:04,405:INFO:          markupsafe: 3.0.3
2025-10-09 18:24:04,405:INFO:             pickle5: Not installed
2025-10-09 18:24:04,405:INFO:         cloudpickle: 3.1.1
2025-10-09 18:24:04,405:INFO:         deprecation: 2.1.0
2025-10-09 18:24:04,405:INFO:              xxhash: 3.6.0
2025-10-09 18:24:04,405:INFO:           wurlitzer: Not installed
2025-10-09 18:24:04,405:INFO:PyCaret optional dependencies:
2025-10-09 18:24:04,423:INFO:                shap: Not installed
2025-10-09 18:24:04,423:INFO:           interpret: Not installed
2025-10-09 18:24:04,423:INFO:                umap: Not installed
2025-10-09 18:24:04,423:INFO:     ydata_profiling: Not installed
2025-10-09 18:24:04,423:INFO:  explainerdashboard: Not installed
2025-10-09 18:24:04,423:INFO:             autoviz: Not installed
2025-10-09 18:24:04,423:INFO:           fairlearn: Not installed
2025-10-09 18:24:04,423:INFO:          deepchecks: Not installed
2025-10-09 18:24:04,423:INFO:             xgboost: Not installed
2025-10-09 18:24:04,423:INFO:            catboost: Not installed
2025-10-09 18:24:04,423:INFO:              kmodes: Not installed
2025-10-09 18:24:04,423:INFO:             mlxtend: Not installed
2025-10-09 18:24:04,423:INFO:       statsforecast: Not installed
2025-10-09 18:24:04,423:INFO:        tune_sklearn: Not installed
2025-10-09 18:24:04,423:INFO:                 ray: Not installed
2025-10-09 18:24:04,423:INFO:            hyperopt: Not installed
2025-10-09 18:24:04,423:INFO:              optuna: Not installed
2025-10-09 18:24:04,423:INFO:               skopt: Not installed
2025-10-09 18:24:04,423:INFO:              mlflow: Not installed
2025-10-09 18:24:04,423:INFO:              gradio: Not installed
2025-10-09 18:24:04,423:INFO:             fastapi: Not installed
2025-10-09 18:24:04,423:INFO:             uvicorn: Not installed
2025-10-09 18:24:04,423:INFO:              m2cgen: Not installed
2025-10-09 18:24:04,423:INFO:           evidently: Not installed
2025-10-09 18:24:04,423:INFO:               fugue: Not installed
2025-10-09 18:24:04,423:INFO:           streamlit: Not installed
2025-10-09 18:24:04,423:INFO:             prophet: Not installed
2025-10-09 18:24:04,423:INFO:None
2025-10-09 18:24:04,424:INFO:Set up data.
2025-10-09 18:24:04,429:INFO:Set up folding strategy.
2025-10-09 18:24:04,429:INFO:Set up train/test split.
2025-10-09 18:24:04,469:INFO:Set up index.
2025-10-09 18:24:04,470:INFO:Assigning column types.
2025-10-09 18:24:04,473:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-09 18:24:04,474:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,481:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,486:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,551:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,600:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,601:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:04,601:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:04,602:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,606:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,613:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,675:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,728:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,729:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:04,729:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:04,729:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-09 18:24:04,735:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,740:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,807:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,857:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:04,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:04,863:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,869:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,932:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,983:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 18:24:04,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:04,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:04,984:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-09 18:24:04,993:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 18:24:05,055:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 18:24:05,105:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 18:24:05,105:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:05,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:05,117:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 18:24:05,181:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 18:24:05,234:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 18:24:05,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:05,235:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:05,236:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-09 18:24:05,309:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 18:24:05,363:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 18:24:05,364:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:05,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:05,439:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 18:24:05,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 18:24:05,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:05,488:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:05,488:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-09 18:24:05,562:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 18:24:05,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:05,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:05,696:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 18:24:05,748:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:05,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:05,748:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-09 18:24:05,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:05,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:06,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:06,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:06,009:INFO:Preparing preprocessing pipeline...
2025-10-09 18:24:06,009:INFO:Set up simple imputation.
2025-10-09 18:24:06,011:INFO:Set up encoding of categorical features.
2025-10-09 18:24:06,011:INFO:Set up feature normalization.
2025-10-09 18:24:06,072:INFO:Finished creating preprocessing pipeline.
2025-10-09 18:24:06,080:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jjqs_\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-10-09 18:24:06,080:INFO:Creating final display dataframe.
2025-10-09 18:24:06,230:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            precio
2                   Target type        Regression
3           Original data shape          (100, 7)
4        Transformed data shape         (100, 10)
5   Transformed train set shape          (70, 10)
6    Transformed test set shape          (30, 10)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              77b4
2025-10-09 18:24:06,371:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:06,372:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:06,494:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:06,495:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:24:06,496:INFO:setup() successfully completed in 2.17s...............
2025-10-09 18:24:10,401:INFO:Initializing compare_models()
2025-10-09 18:24:10,401:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-10-09 18:24:10,401:INFO:Checking exceptions
2025-10-09 18:24:10,404:INFO:Preparing display monitor
2025-10-09 18:24:10,434:INFO:Initializing Linear Regression
2025-10-09 18:24:10,434:INFO:Total runtime is 0.0 minutes
2025-10-09 18:24:10,438:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:10,439:INFO:Initializing create_model()
2025-10-09 18:24:10,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:10,439:INFO:Checking exceptions
2025-10-09 18:24:10,439:INFO:Importing libraries
2025-10-09 18:24:10,439:INFO:Copying training dataset
2025-10-09 18:24:10,443:INFO:Defining folds
2025-10-09 18:24:10,443:INFO:Declaring metric variables
2025-10-09 18:24:10,448:INFO:Importing untrained model
2025-10-09 18:24:10,454:INFO:Linear Regression Imported successfully
2025-10-09 18:24:10,464:INFO:Starting cross validation
2025-10-09 18:24:10,472:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:17,070:INFO:Calculating mean and std
2025-10-09 18:24:17,074:INFO:Creating metrics dataframe
2025-10-09 18:24:17,078:INFO:Uploading results into container
2025-10-09 18:24:17,079:INFO:Uploading model into container now
2025-10-09 18:24:17,081:INFO:_master_model_container: 1
2025-10-09 18:24:17,081:INFO:_display_container: 2
2025-10-09 18:24:17,081:INFO:LinearRegression(n_jobs=-1)
2025-10-09 18:24:17,082:INFO:create_model() successfully completed......................................
2025-10-09 18:24:17,207:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:17,207:INFO:Creating metrics dataframe
2025-10-09 18:24:17,213:INFO:Initializing Lasso Regression
2025-10-09 18:24:17,213:INFO:Total runtime is 0.11299184560775757 minutes
2025-10-09 18:24:17,217:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:17,217:INFO:Initializing create_model()
2025-10-09 18:24:17,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:17,218:INFO:Checking exceptions
2025-10-09 18:24:17,218:INFO:Importing libraries
2025-10-09 18:24:17,218:INFO:Copying training dataset
2025-10-09 18:24:17,222:INFO:Defining folds
2025-10-09 18:24:17,222:INFO:Declaring metric variables
2025-10-09 18:24:17,226:INFO:Importing untrained model
2025-10-09 18:24:17,229:INFO:Lasso Regression Imported successfully
2025-10-09 18:24:17,238:INFO:Starting cross validation
2025-10-09 18:24:17,240:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:20,250:INFO:Calculating mean and std
2025-10-09 18:24:20,252:INFO:Creating metrics dataframe
2025-10-09 18:24:20,254:INFO:Uploading results into container
2025-10-09 18:24:20,255:INFO:Uploading model into container now
2025-10-09 18:24:20,255:INFO:_master_model_container: 2
2025-10-09 18:24:20,255:INFO:_display_container: 2
2025-10-09 18:24:20,256:INFO:Lasso(random_state=123)
2025-10-09 18:24:20,256:INFO:create_model() successfully completed......................................
2025-10-09 18:24:20,338:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:20,338:INFO:Creating metrics dataframe
2025-10-09 18:24:20,345:INFO:Initializing Ridge Regression
2025-10-09 18:24:20,345:INFO:Total runtime is 0.16519164641698203 minutes
2025-10-09 18:24:20,348:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:20,348:INFO:Initializing create_model()
2025-10-09 18:24:20,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:20,349:INFO:Checking exceptions
2025-10-09 18:24:20,349:INFO:Importing libraries
2025-10-09 18:24:20,349:INFO:Copying training dataset
2025-10-09 18:24:20,353:INFO:Defining folds
2025-10-09 18:24:20,353:INFO:Declaring metric variables
2025-10-09 18:24:20,357:INFO:Importing untrained model
2025-10-09 18:24:20,360:INFO:Ridge Regression Imported successfully
2025-10-09 18:24:20,369:INFO:Starting cross validation
2025-10-09 18:24:20,371:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:20,545:INFO:Calculating mean and std
2025-10-09 18:24:20,547:INFO:Creating metrics dataframe
2025-10-09 18:24:20,548:INFO:Uploading results into container
2025-10-09 18:24:20,549:INFO:Uploading model into container now
2025-10-09 18:24:20,550:INFO:_master_model_container: 3
2025-10-09 18:24:20,550:INFO:_display_container: 2
2025-10-09 18:24:20,550:INFO:Ridge(random_state=123)
2025-10-09 18:24:20,550:INFO:create_model() successfully completed......................................
2025-10-09 18:24:20,621:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:20,621:INFO:Creating metrics dataframe
2025-10-09 18:24:20,628:INFO:Initializing Elastic Net
2025-10-09 18:24:20,628:INFO:Total runtime is 0.1699142058690389 minutes
2025-10-09 18:24:20,632:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:20,632:INFO:Initializing create_model()
2025-10-09 18:24:20,632:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:20,632:INFO:Checking exceptions
2025-10-09 18:24:20,632:INFO:Importing libraries
2025-10-09 18:24:20,632:INFO:Copying training dataset
2025-10-09 18:24:20,636:INFO:Defining folds
2025-10-09 18:24:20,636:INFO:Declaring metric variables
2025-10-09 18:24:20,639:INFO:Importing untrained model
2025-10-09 18:24:20,643:INFO:Elastic Net Imported successfully
2025-10-09 18:24:20,650:INFO:Starting cross validation
2025-10-09 18:24:20,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:20,811:INFO:Calculating mean and std
2025-10-09 18:24:20,812:INFO:Creating metrics dataframe
2025-10-09 18:24:20,814:INFO:Uploading results into container
2025-10-09 18:24:20,814:INFO:Uploading model into container now
2025-10-09 18:24:20,815:INFO:_master_model_container: 4
2025-10-09 18:24:20,815:INFO:_display_container: 2
2025-10-09 18:24:20,815:INFO:ElasticNet(random_state=123)
2025-10-09 18:24:20,815:INFO:create_model() successfully completed......................................
2025-10-09 18:24:20,885:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:20,885:INFO:Creating metrics dataframe
2025-10-09 18:24:20,891:INFO:Initializing Least Angle Regression
2025-10-09 18:24:20,892:INFO:Total runtime is 0.1743046204249064 minutes
2025-10-09 18:24:20,895:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:20,895:INFO:Initializing create_model()
2025-10-09 18:24:20,896:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:20,896:INFO:Checking exceptions
2025-10-09 18:24:20,896:INFO:Importing libraries
2025-10-09 18:24:20,896:INFO:Copying training dataset
2025-10-09 18:24:20,899:INFO:Defining folds
2025-10-09 18:24:20,899:INFO:Declaring metric variables
2025-10-09 18:24:20,903:INFO:Importing untrained model
2025-10-09 18:24:20,907:INFO:Least Angle Regression Imported successfully
2025-10-09 18:24:20,915:INFO:Starting cross validation
2025-10-09 18:24:20,916:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:21,075:INFO:Calculating mean and std
2025-10-09 18:24:21,076:INFO:Creating metrics dataframe
2025-10-09 18:24:21,079:INFO:Uploading results into container
2025-10-09 18:24:21,080:INFO:Uploading model into container now
2025-10-09 18:24:21,080:INFO:_master_model_container: 5
2025-10-09 18:24:21,081:INFO:_display_container: 2
2025-10-09 18:24:21,081:INFO:Lars(random_state=123)
2025-10-09 18:24:21,081:INFO:create_model() successfully completed......................................
2025-10-09 18:24:21,151:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:21,151:INFO:Creating metrics dataframe
2025-10-09 18:24:21,159:INFO:Initializing Lasso Least Angle Regression
2025-10-09 18:24:21,159:INFO:Total runtime is 0.17876544793446858 minutes
2025-10-09 18:24:21,163:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:21,164:INFO:Initializing create_model()
2025-10-09 18:24:21,164:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:21,164:INFO:Checking exceptions
2025-10-09 18:24:21,164:INFO:Importing libraries
2025-10-09 18:24:21,164:INFO:Copying training dataset
2025-10-09 18:24:21,169:INFO:Defining folds
2025-10-09 18:24:21,169:INFO:Declaring metric variables
2025-10-09 18:24:21,172:INFO:Importing untrained model
2025-10-09 18:24:21,176:INFO:Lasso Least Angle Regression Imported successfully
2025-10-09 18:24:21,185:INFO:Starting cross validation
2025-10-09 18:24:21,187:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:21,355:INFO:Calculating mean and std
2025-10-09 18:24:21,356:INFO:Creating metrics dataframe
2025-10-09 18:24:21,358:INFO:Uploading results into container
2025-10-09 18:24:21,359:INFO:Uploading model into container now
2025-10-09 18:24:21,360:INFO:_master_model_container: 6
2025-10-09 18:24:21,360:INFO:_display_container: 2
2025-10-09 18:24:21,360:INFO:LassoLars(random_state=123)
2025-10-09 18:24:21,360:INFO:create_model() successfully completed......................................
2025-10-09 18:24:21,432:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:21,432:INFO:Creating metrics dataframe
2025-10-09 18:24:21,439:INFO:Initializing Orthogonal Matching Pursuit
2025-10-09 18:24:21,439:INFO:Total runtime is 0.183428156375885 minutes
2025-10-09 18:24:21,442:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:21,443:INFO:Initializing create_model()
2025-10-09 18:24:21,443:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:21,443:INFO:Checking exceptions
2025-10-09 18:24:21,443:INFO:Importing libraries
2025-10-09 18:24:21,443:INFO:Copying training dataset
2025-10-09 18:24:21,447:INFO:Defining folds
2025-10-09 18:24:21,447:INFO:Declaring metric variables
2025-10-09 18:24:21,450:INFO:Importing untrained model
2025-10-09 18:24:21,453:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-09 18:24:21,461:INFO:Starting cross validation
2025-10-09 18:24:21,462:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:21,622:INFO:Calculating mean and std
2025-10-09 18:24:21,623:INFO:Creating metrics dataframe
2025-10-09 18:24:21,625:INFO:Uploading results into container
2025-10-09 18:24:21,626:INFO:Uploading model into container now
2025-10-09 18:24:21,626:INFO:_master_model_container: 7
2025-10-09 18:24:21,626:INFO:_display_container: 2
2025-10-09 18:24:21,627:INFO:OrthogonalMatchingPursuit()
2025-10-09 18:24:21,627:INFO:create_model() successfully completed......................................
2025-10-09 18:24:21,699:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:21,699:INFO:Creating metrics dataframe
2025-10-09 18:24:21,706:INFO:Initializing Bayesian Ridge
2025-10-09 18:24:21,707:INFO:Total runtime is 0.18789851268132526 minutes
2025-10-09 18:24:21,710:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:21,711:INFO:Initializing create_model()
2025-10-09 18:24:21,711:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:21,711:INFO:Checking exceptions
2025-10-09 18:24:21,711:INFO:Importing libraries
2025-10-09 18:24:21,711:INFO:Copying training dataset
2025-10-09 18:24:21,715:INFO:Defining folds
2025-10-09 18:24:21,715:INFO:Declaring metric variables
2025-10-09 18:24:21,718:INFO:Importing untrained model
2025-10-09 18:24:21,723:INFO:Bayesian Ridge Imported successfully
2025-10-09 18:24:21,732:INFO:Starting cross validation
2025-10-09 18:24:21,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:21,890:INFO:Calculating mean and std
2025-10-09 18:24:21,890:INFO:Creating metrics dataframe
2025-10-09 18:24:21,892:INFO:Uploading results into container
2025-10-09 18:24:21,893:INFO:Uploading model into container now
2025-10-09 18:24:21,894:INFO:_master_model_container: 8
2025-10-09 18:24:21,894:INFO:_display_container: 2
2025-10-09 18:24:21,894:INFO:BayesianRidge()
2025-10-09 18:24:21,894:INFO:create_model() successfully completed......................................
2025-10-09 18:24:21,968:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:21,969:INFO:Creating metrics dataframe
2025-10-09 18:24:21,977:INFO:Initializing Passive Aggressive Regressor
2025-10-09 18:24:21,977:INFO:Total runtime is 0.19239338239034015 minutes
2025-10-09 18:24:21,981:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:21,982:INFO:Initializing create_model()
2025-10-09 18:24:21,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:21,982:INFO:Checking exceptions
2025-10-09 18:24:21,982:INFO:Importing libraries
2025-10-09 18:24:21,982:INFO:Copying training dataset
2025-10-09 18:24:21,987:INFO:Defining folds
2025-10-09 18:24:21,988:INFO:Declaring metric variables
2025-10-09 18:24:21,992:INFO:Importing untrained model
2025-10-09 18:24:21,998:INFO:Passive Aggressive Regressor Imported successfully
2025-10-09 18:24:22,009:INFO:Starting cross validation
2025-10-09 18:24:22,011:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:22,096:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 18:24:22,101:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 18:24:22,111:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 18:24:22,118:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 18:24:22,123:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 18:24:22,129:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 18:24:22,140:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 18:24:22,141:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 18:24:22,143:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 18:24:22,145:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 18:24:22,188:INFO:Calculating mean and std
2025-10-09 18:24:22,189:INFO:Creating metrics dataframe
2025-10-09 18:24:22,191:INFO:Uploading results into container
2025-10-09 18:24:22,192:INFO:Uploading model into container now
2025-10-09 18:24:22,192:INFO:_master_model_container: 9
2025-10-09 18:24:22,192:INFO:_display_container: 2
2025-10-09 18:24:22,193:INFO:PassiveAggressiveRegressor(random_state=123)
2025-10-09 18:24:22,193:INFO:create_model() successfully completed......................................
2025-10-09 18:24:22,262:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:22,262:INFO:Creating metrics dataframe
2025-10-09 18:24:22,271:INFO:Initializing Huber Regressor
2025-10-09 18:24:22,271:INFO:Total runtime is 0.19729386170705157 minutes
2025-10-09 18:24:22,275:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:22,275:INFO:Initializing create_model()
2025-10-09 18:24:22,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:22,275:INFO:Checking exceptions
2025-10-09 18:24:22,276:INFO:Importing libraries
2025-10-09 18:24:22,276:INFO:Copying training dataset
2025-10-09 18:24:22,279:INFO:Defining folds
2025-10-09 18:24:22,279:INFO:Declaring metric variables
2025-10-09 18:24:22,282:INFO:Importing untrained model
2025-10-09 18:24:22,286:INFO:Huber Regressor Imported successfully
2025-10-09 18:24:22,294:INFO:Starting cross validation
2025-10-09 18:24:22,296:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:22,467:INFO:Calculating mean and std
2025-10-09 18:24:22,468:INFO:Creating metrics dataframe
2025-10-09 18:24:22,470:INFO:Uploading results into container
2025-10-09 18:24:22,471:INFO:Uploading model into container now
2025-10-09 18:24:22,471:INFO:_master_model_container: 10
2025-10-09 18:24:22,472:INFO:_display_container: 2
2025-10-09 18:24:22,472:INFO:HuberRegressor()
2025-10-09 18:24:22,472:INFO:create_model() successfully completed......................................
2025-10-09 18:24:22,547:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:22,547:INFO:Creating metrics dataframe
2025-10-09 18:24:22,555:INFO:Initializing K Neighbors Regressor
2025-10-09 18:24:22,555:INFO:Total runtime is 0.20202479759852088 minutes
2025-10-09 18:24:22,559:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:22,559:INFO:Initializing create_model()
2025-10-09 18:24:22,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:22,559:INFO:Checking exceptions
2025-10-09 18:24:22,559:INFO:Importing libraries
2025-10-09 18:24:22,559:INFO:Copying training dataset
2025-10-09 18:24:22,565:INFO:Defining folds
2025-10-09 18:24:22,565:INFO:Declaring metric variables
2025-10-09 18:24:22,568:INFO:Importing untrained model
2025-10-09 18:24:22,572:INFO:K Neighbors Regressor Imported successfully
2025-10-09 18:24:22,582:INFO:Starting cross validation
2025-10-09 18:24:22,583:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:22,798:INFO:Calculating mean and std
2025-10-09 18:24:22,799:INFO:Creating metrics dataframe
2025-10-09 18:24:22,801:INFO:Uploading results into container
2025-10-09 18:24:22,802:INFO:Uploading model into container now
2025-10-09 18:24:22,803:INFO:_master_model_container: 11
2025-10-09 18:24:22,803:INFO:_display_container: 2
2025-10-09 18:24:22,803:INFO:KNeighborsRegressor(n_jobs=-1)
2025-10-09 18:24:22,803:INFO:create_model() successfully completed......................................
2025-10-09 18:24:22,879:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:22,879:INFO:Creating metrics dataframe
2025-10-09 18:24:22,887:INFO:Initializing Decision Tree Regressor
2025-10-09 18:24:22,888:INFO:Total runtime is 0.2075656453768412 minutes
2025-10-09 18:24:22,892:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:22,893:INFO:Initializing create_model()
2025-10-09 18:24:22,893:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:22,893:INFO:Checking exceptions
2025-10-09 18:24:22,893:INFO:Importing libraries
2025-10-09 18:24:22,893:INFO:Copying training dataset
2025-10-09 18:24:22,899:INFO:Defining folds
2025-10-09 18:24:22,899:INFO:Declaring metric variables
2025-10-09 18:24:22,902:INFO:Importing untrained model
2025-10-09 18:24:22,906:INFO:Decision Tree Regressor Imported successfully
2025-10-09 18:24:22,919:INFO:Starting cross validation
2025-10-09 18:24:22,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:23,079:INFO:Calculating mean and std
2025-10-09 18:24:23,080:INFO:Creating metrics dataframe
2025-10-09 18:24:23,082:INFO:Uploading results into container
2025-10-09 18:24:23,083:INFO:Uploading model into container now
2025-10-09 18:24:23,084:INFO:_master_model_container: 12
2025-10-09 18:24:23,084:INFO:_display_container: 2
2025-10-09 18:24:23,084:INFO:DecisionTreeRegressor(random_state=123)
2025-10-09 18:24:23,084:INFO:create_model() successfully completed......................................
2025-10-09 18:24:23,160:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:23,160:INFO:Creating metrics dataframe
2025-10-09 18:24:23,169:INFO:Initializing Random Forest Regressor
2025-10-09 18:24:23,169:INFO:Total runtime is 0.21225474675496417 minutes
2025-10-09 18:24:23,172:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:23,173:INFO:Initializing create_model()
2025-10-09 18:24:23,173:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:23,173:INFO:Checking exceptions
2025-10-09 18:24:23,173:INFO:Importing libraries
2025-10-09 18:24:23,173:INFO:Copying training dataset
2025-10-09 18:24:23,176:INFO:Defining folds
2025-10-09 18:24:23,176:INFO:Declaring metric variables
2025-10-09 18:24:23,179:INFO:Importing untrained model
2025-10-09 18:24:23,183:INFO:Random Forest Regressor Imported successfully
2025-10-09 18:24:23,193:INFO:Starting cross validation
2025-10-09 18:24:23,195:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:23,684:INFO:Calculating mean and std
2025-10-09 18:24:23,684:INFO:Creating metrics dataframe
2025-10-09 18:24:23,686:INFO:Uploading results into container
2025-10-09 18:24:23,687:INFO:Uploading model into container now
2025-10-09 18:24:23,687:INFO:_master_model_container: 13
2025-10-09 18:24:23,688:INFO:_display_container: 2
2025-10-09 18:24:23,688:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-10-09 18:24:23,688:INFO:create_model() successfully completed......................................
2025-10-09 18:24:23,758:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:23,759:INFO:Creating metrics dataframe
2025-10-09 18:24:23,767:INFO:Initializing Extra Trees Regressor
2025-10-09 18:24:23,768:INFO:Total runtime is 0.22223931153615314 minutes
2025-10-09 18:24:23,771:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:23,771:INFO:Initializing create_model()
2025-10-09 18:24:23,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:23,772:INFO:Checking exceptions
2025-10-09 18:24:23,772:INFO:Importing libraries
2025-10-09 18:24:23,772:INFO:Copying training dataset
2025-10-09 18:24:23,775:INFO:Defining folds
2025-10-09 18:24:23,775:INFO:Declaring metric variables
2025-10-09 18:24:23,780:INFO:Importing untrained model
2025-10-09 18:24:23,784:INFO:Extra Trees Regressor Imported successfully
2025-10-09 18:24:23,793:INFO:Starting cross validation
2025-10-09 18:24:23,795:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:24,182:INFO:Calculating mean and std
2025-10-09 18:24:24,183:INFO:Creating metrics dataframe
2025-10-09 18:24:24,186:INFO:Uploading results into container
2025-10-09 18:24:24,187:INFO:Uploading model into container now
2025-10-09 18:24:24,188:INFO:_master_model_container: 14
2025-10-09 18:24:24,188:INFO:_display_container: 2
2025-10-09 18:24:24,189:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-10-09 18:24:24,189:INFO:create_model() successfully completed......................................
2025-10-09 18:24:24,283:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:24,283:INFO:Creating metrics dataframe
2025-10-09 18:24:24,293:INFO:Initializing AdaBoost Regressor
2025-10-09 18:24:24,293:INFO:Total runtime is 0.23098809321721395 minutes
2025-10-09 18:24:24,297:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:24,297:INFO:Initializing create_model()
2025-10-09 18:24:24,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:24,297:INFO:Checking exceptions
2025-10-09 18:24:24,298:INFO:Importing libraries
2025-10-09 18:24:24,298:INFO:Copying training dataset
2025-10-09 18:24:24,300:INFO:Defining folds
2025-10-09 18:24:24,301:INFO:Declaring metric variables
2025-10-09 18:24:24,304:INFO:Importing untrained model
2025-10-09 18:24:24,308:INFO:AdaBoost Regressor Imported successfully
2025-10-09 18:24:24,316:INFO:Starting cross validation
2025-10-09 18:24:24,318:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:24,604:INFO:Calculating mean and std
2025-10-09 18:24:24,605:INFO:Creating metrics dataframe
2025-10-09 18:24:24,607:INFO:Uploading results into container
2025-10-09 18:24:24,608:INFO:Uploading model into container now
2025-10-09 18:24:24,609:INFO:_master_model_container: 15
2025-10-09 18:24:24,609:INFO:_display_container: 2
2025-10-09 18:24:24,609:INFO:AdaBoostRegressor(random_state=123)
2025-10-09 18:24:24,609:INFO:create_model() successfully completed......................................
2025-10-09 18:24:24,687:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:24,687:INFO:Creating metrics dataframe
2025-10-09 18:24:24,696:INFO:Initializing Gradient Boosting Regressor
2025-10-09 18:24:24,697:INFO:Total runtime is 0.23772767782211304 minutes
2025-10-09 18:24:24,700:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:24,700:INFO:Initializing create_model()
2025-10-09 18:24:24,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:24,701:INFO:Checking exceptions
2025-10-09 18:24:24,701:INFO:Importing libraries
2025-10-09 18:24:24,701:INFO:Copying training dataset
2025-10-09 18:24:24,705:INFO:Defining folds
2025-10-09 18:24:24,706:INFO:Declaring metric variables
2025-10-09 18:24:24,710:INFO:Importing untrained model
2025-10-09 18:24:24,714:INFO:Gradient Boosting Regressor Imported successfully
2025-10-09 18:24:24,724:INFO:Starting cross validation
2025-10-09 18:24:24,726:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:25,026:INFO:Calculating mean and std
2025-10-09 18:24:25,027:INFO:Creating metrics dataframe
2025-10-09 18:24:25,029:INFO:Uploading results into container
2025-10-09 18:24:25,030:INFO:Uploading model into container now
2025-10-09 18:24:25,030:INFO:_master_model_container: 16
2025-10-09 18:24:25,030:INFO:_display_container: 2
2025-10-09 18:24:25,031:INFO:GradientBoostingRegressor(random_state=123)
2025-10-09 18:24:25,031:INFO:create_model() successfully completed......................................
2025-10-09 18:24:25,100:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:25,101:INFO:Creating metrics dataframe
2025-10-09 18:24:25,111:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 18:24:25,111:INFO:Total runtime is 0.24462300936381023 minutes
2025-10-09 18:24:25,115:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:25,115:INFO:Initializing create_model()
2025-10-09 18:24:25,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:25,116:INFO:Checking exceptions
2025-10-09 18:24:25,116:INFO:Importing libraries
2025-10-09 18:24:25,116:INFO:Copying training dataset
2025-10-09 18:24:25,119:INFO:Defining folds
2025-10-09 18:24:25,119:INFO:Declaring metric variables
2025-10-09 18:24:25,123:INFO:Importing untrained model
2025-10-09 18:24:25,128:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 18:24:25,138:INFO:Starting cross validation
2025-10-09 18:24:25,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:25,479:INFO:Calculating mean and std
2025-10-09 18:24:25,480:INFO:Creating metrics dataframe
2025-10-09 18:24:25,482:INFO:Uploading results into container
2025-10-09 18:24:25,483:INFO:Uploading model into container now
2025-10-09 18:24:25,483:INFO:_master_model_container: 17
2025-10-09 18:24:25,484:INFO:_display_container: 2
2025-10-09 18:24:25,484:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-10-09 18:24:25,484:INFO:create_model() successfully completed......................................
2025-10-09 18:24:25,572:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:25,572:INFO:Creating metrics dataframe
2025-10-09 18:24:25,582:INFO:Initializing Dummy Regressor
2025-10-09 18:24:25,583:INFO:Total runtime is 0.2524979631106059 minutes
2025-10-09 18:24:25,585:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:25,586:INFO:Initializing create_model()
2025-10-09 18:24:25,586:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E259302F80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:25,586:INFO:Checking exceptions
2025-10-09 18:24:25,586:INFO:Importing libraries
2025-10-09 18:24:25,586:INFO:Copying training dataset
2025-10-09 18:24:25,590:INFO:Defining folds
2025-10-09 18:24:25,590:INFO:Declaring metric variables
2025-10-09 18:24:25,593:INFO:Importing untrained model
2025-10-09 18:24:25,597:INFO:Dummy Regressor Imported successfully
2025-10-09 18:24:25,607:INFO:Starting cross validation
2025-10-09 18:24:25,609:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:25,759:INFO:Calculating mean and std
2025-10-09 18:24:25,760:INFO:Creating metrics dataframe
2025-10-09 18:24:25,763:INFO:Uploading results into container
2025-10-09 18:24:25,763:INFO:Uploading model into container now
2025-10-09 18:24:25,764:INFO:_master_model_container: 18
2025-10-09 18:24:25,764:INFO:_display_container: 2
2025-10-09 18:24:25,764:INFO:DummyRegressor()
2025-10-09 18:24:25,764:INFO:create_model() successfully completed......................................
2025-10-09 18:24:25,839:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:25,839:INFO:Creating metrics dataframe
2025-10-09 18:24:25,849:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-10-09 18:24:25,858:INFO:Initializing create_model()
2025-10-09 18:24:25,858:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:25,858:INFO:Checking exceptions
2025-10-09 18:24:25,860:INFO:Importing libraries
2025-10-09 18:24:25,860:INFO:Copying training dataset
2025-10-09 18:24:25,863:INFO:Defining folds
2025-10-09 18:24:25,863:INFO:Declaring metric variables
2025-10-09 18:24:25,863:INFO:Importing untrained model
2025-10-09 18:24:25,863:INFO:Declaring custom model
2025-10-09 18:24:25,864:INFO:Linear Regression Imported successfully
2025-10-09 18:24:25,865:INFO:Cross validation set to False
2025-10-09 18:24:25,865:INFO:Fitting Model
2025-10-09 18:24:25,902:INFO:LinearRegression(n_jobs=-1)
2025-10-09 18:24:25,902:INFO:create_model() successfully completed......................................
2025-10-09 18:24:26,004:INFO:_master_model_container: 18
2025-10-09 18:24:26,004:INFO:_display_container: 2
2025-10-09 18:24:26,004:INFO:LinearRegression(n_jobs=-1)
2025-10-09 18:24:26,004:INFO:compare_models() successfully completed......................................
2025-10-09 18:24:37,813:INFO:Initializing create_model()
2025-10-09 18:24:37,813:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:37,813:INFO:Checking exceptions
2025-10-09 18:24:37,831:INFO:Importing libraries
2025-10-09 18:24:37,832:INFO:Copying training dataset
2025-10-09 18:24:37,838:INFO:Defining folds
2025-10-09 18:24:37,839:INFO:Declaring metric variables
2025-10-09 18:24:37,843:INFO:Importing untrained model
2025-10-09 18:24:37,848:INFO:Linear Regression Imported successfully
2025-10-09 18:24:37,856:INFO:Starting cross validation
2025-10-09 18:24:37,858:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:38,035:INFO:Calculating mean and std
2025-10-09 18:24:38,036:INFO:Creating metrics dataframe
2025-10-09 18:24:38,041:INFO:Finalizing model
2025-10-09 18:24:38,078:INFO:Uploading results into container
2025-10-09 18:24:38,079:INFO:Uploading model into container now
2025-10-09 18:24:38,090:INFO:_master_model_container: 19
2025-10-09 18:24:38,090:INFO:_display_container: 3
2025-10-09 18:24:38,090:INFO:LinearRegression(n_jobs=-1)
2025-10-09 18:24:38,092:INFO:create_model() successfully completed......................................
2025-10-09 18:24:44,098:INFO:Initializing tune_model()
2025-10-09 18:24:44,099:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>)
2025-10-09 18:24:44,099:INFO:Checking exceptions
2025-10-09 18:24:44,121:INFO:Copying training dataset
2025-10-09 18:24:44,125:INFO:Checking base model
2025-10-09 18:24:44,126:INFO:Base model : Linear Regression
2025-10-09 18:24:44,130:INFO:Declaring metric variables
2025-10-09 18:24:44,133:INFO:Defining Hyperparameters
2025-10-09 18:24:44,134:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-10-09 18:24:44,207:INFO:Tuning with n_jobs=-1
2025-10-09 18:24:44,207:INFO:Initializing GridSearchCV
2025-10-09 18:24:44,444:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-10-09 18:24:44,444:INFO:Hyperparameter search completed
2025-10-09 18:24:44,444:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:44,444:INFO:Initializing create_model()
2025-10-09 18:24:44,444:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E20B575420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True})
2025-10-09 18:24:44,444:INFO:Checking exceptions
2025-10-09 18:24:44,444:INFO:Importing libraries
2025-10-09 18:24:44,444:INFO:Copying training dataset
2025-10-09 18:24:44,447:INFO:Defining folds
2025-10-09 18:24:44,447:INFO:Declaring metric variables
2025-10-09 18:24:44,451:INFO:Importing untrained model
2025-10-09 18:24:44,451:INFO:Declaring custom model
2025-10-09 18:24:44,454:INFO:Linear Regression Imported successfully
2025-10-09 18:24:44,461:INFO:Starting cross validation
2025-10-09 18:24:44,463:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:44,616:INFO:Calculating mean and std
2025-10-09 18:24:44,617:INFO:Creating metrics dataframe
2025-10-09 18:24:44,621:INFO:Finalizing model
2025-10-09 18:24:44,654:INFO:Uploading results into container
2025-10-09 18:24:44,655:INFO:Uploading model into container now
2025-10-09 18:24:44,655:INFO:_master_model_container: 20
2025-10-09 18:24:44,656:INFO:_display_container: 4
2025-10-09 18:24:44,656:INFO:LinearRegression(n_jobs=-1)
2025-10-09 18:24:44,656:INFO:create_model() successfully completed......................................
2025-10-09 18:24:44,729:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:44,729:INFO:choose_better activated
2025-10-09 18:24:44,732:INFO:SubProcess create_model() called ==================================
2025-10-09 18:24:44,733:INFO:Initializing create_model()
2025-10-09 18:24:44,733:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:24:44,733:INFO:Checking exceptions
2025-10-09 18:24:44,734:INFO:Importing libraries
2025-10-09 18:24:44,735:INFO:Copying training dataset
2025-10-09 18:24:44,738:INFO:Defining folds
2025-10-09 18:24:44,738:INFO:Declaring metric variables
2025-10-09 18:24:44,738:INFO:Importing untrained model
2025-10-09 18:24:44,738:INFO:Declaring custom model
2025-10-09 18:24:44,738:INFO:Linear Regression Imported successfully
2025-10-09 18:24:44,738:INFO:Starting cross validation
2025-10-09 18:24:44,739:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:24:44,897:INFO:Calculating mean and std
2025-10-09 18:24:44,897:INFO:Creating metrics dataframe
2025-10-09 18:24:44,899:INFO:Finalizing model
2025-10-09 18:24:44,926:INFO:Uploading results into container
2025-10-09 18:24:44,926:INFO:Uploading model into container now
2025-10-09 18:24:44,927:INFO:_master_model_container: 21
2025-10-09 18:24:44,927:INFO:_display_container: 5
2025-10-09 18:24:44,927:INFO:LinearRegression(n_jobs=-1)
2025-10-09 18:24:44,927:INFO:create_model() successfully completed......................................
2025-10-09 18:24:44,999:INFO:SubProcess create_model() end ==================================
2025-10-09 18:24:44,999:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9593
2025-10-09 18:24:44,999:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9593
2025-10-09 18:24:45,000:INFO:LinearRegression(n_jobs=-1) is best model
2025-10-09 18:24:45,000:INFO:choose_better completed
2025-10-09 18:24:45,000:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-09 18:24:45,010:INFO:_master_model_container: 21
2025-10-09 18:24:45,010:INFO:_display_container: 4
2025-10-09 18:24:45,010:INFO:LinearRegression(n_jobs=-1)
2025-10-09 18:24:45,010:INFO:tune_model() successfully completed......................................
2025-10-09 18:24:48,817:INFO:Initializing evaluate_model()
2025-10-09 18:24:48,818:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-09 18:24:48,829:INFO:Initializing plot_model()
2025-10-09 18:24:48,830:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, system=True)
2025-10-09 18:24:48,830:INFO:Checking exceptions
2025-10-09 18:24:48,831:INFO:Preloading libraries
2025-10-09 18:24:48,832:INFO:Copying training dataset
2025-10-09 18:24:48,832:INFO:Plot type: pipeline
2025-10-09 18:24:49,035:INFO:Visual Rendered Successfully
2025-10-09 18:24:49,111:INFO:plot_model() successfully completed......................................
2025-10-09 18:24:51,857:INFO:Initializing predict_model()
2025-10-09 18:24:51,858:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E20C00EA10>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E20C4A3F40>)
2025-10-09 18:24:51,858:INFO:Checking exceptions
2025-10-09 18:24:51,859:INFO:Preloading libraries
2025-10-09 18:24:51,947:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-10-09 18:24:59,288:INFO:Initializing save_model()
2025-10-09 18:24:59,288:INFO:save_model(model=LinearRegression(n_jobs=-1), model_name=modelo_precio_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jjqs_\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-10-09 18:24:59,288:INFO:Adding model into prep_pipe
2025-10-09 18:24:59,296:INFO:modelo_precio_final.pkl saved in current working directory
2025-10-09 18:24:59,304:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', LinearRegression(n_jobs=-1))])
2025-10-09 18:24:59,304:INFO:save_model() successfully completed......................................
2025-10-09 18:25:26,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 18:25:26,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 18:25:26,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 18:25:26,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 18:25:36,073:INFO:PyCaret ClassificationExperiment
2025-10-09 18:25:36,073:INFO:Logging name: clf-default-name
2025-10-09 18:25:36,073:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-09 18:25:36,073:INFO:version 3.3.2
2025-10-09 18:25:36,073:INFO:Initializing setup()
2025-10-09 18:25:36,073:INFO:self.USI: 3d84
2025-10-09 18:25:36,073:INFO:self._variable_keys: {'html_param', 'gpu_param', 'target_param', 'fold_generator', 'pipeline', 'exp_id', 'X', 'y_test', 'exp_name_log', 'fold_groups_param', 'fold_shuffle_param', '_available_plots', 'X_test', 'X_train', 'y_train', 'idx', 'USI', 'is_multiclass', 'n_jobs_param', 'memory', '_ml_usecase', 'log_plots_param', 'gpu_n_jobs_param', 'logging_param', 'fix_imbalance', 'y', 'seed', 'data'}
2025-10-09 18:25:36,073:INFO:Checking environment
2025-10-09 18:25:36,073:INFO:python_version: 3.10.0
2025-10-09 18:25:36,073:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-10-09 18:25:36,073:INFO:machine: AMD64
2025-10-09 18:25:36,073:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-09 18:25:36,074:INFO:Memory: svmem(total=17042837504, available=4322304000, percent=74.6, used=12720533504, free=4322304000)
2025-10-09 18:25:36,074:INFO:Physical Core: 6
2025-10-09 18:25:36,074:INFO:Logical Core: 12
2025-10-09 18:25:36,074:INFO:Checking libraries
2025-10-09 18:25:36,074:INFO:System:
2025-10-09 18:25:36,074:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-10-09 18:25:36,074:INFO:executable: c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\python.exe
2025-10-09 18:25:36,074:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-09 18:25:36,074:INFO:PyCaret required dependencies:
2025-10-09 18:25:36,107:INFO:                 pip: 25.2
2025-10-09 18:25:36,107:INFO:          setuptools: 80.9.0
2025-10-09 18:25:36,107:INFO:             pycaret: 3.3.2
2025-10-09 18:25:36,107:INFO:             IPython: 8.37.0
2025-10-09 18:25:36,107:INFO:          ipywidgets: 8.1.7
2025-10-09 18:25:36,107:INFO:                tqdm: 4.67.1
2025-10-09 18:25:36,107:INFO:               numpy: 1.26.4
2025-10-09 18:25:36,107:INFO:              pandas: 2.1.4
2025-10-09 18:25:36,107:INFO:              jinja2: 3.1.6
2025-10-09 18:25:36,107:INFO:               scipy: 1.11.4
2025-10-09 18:25:36,107:INFO:              joblib: 1.3.2
2025-10-09 18:25:36,107:INFO:             sklearn: 1.4.2
2025-10-09 18:25:36,107:INFO:                pyod: 2.0.5
2025-10-09 18:25:36,107:INFO:            imblearn: 0.14.0
2025-10-09 18:25:36,107:INFO:   category_encoders: 2.7.0
2025-10-09 18:25:36,107:INFO:            lightgbm: 4.6.0
2025-10-09 18:25:36,107:INFO:               numba: 0.62.1
2025-10-09 18:25:36,107:INFO:            requests: 2.32.5
2025-10-09 18:25:36,107:INFO:          matplotlib: 3.7.5
2025-10-09 18:25:36,107:INFO:          scikitplot: 0.3.7
2025-10-09 18:25:36,108:INFO:         yellowbrick: 1.5
2025-10-09 18:25:36,108:INFO:              plotly: 6.3.1
2025-10-09 18:25:36,108:INFO:    plotly-resampler: Not installed
2025-10-09 18:25:36,108:INFO:             kaleido: 1.1.0
2025-10-09 18:25:36,108:INFO:           schemdraw: 0.15
2025-10-09 18:25:36,108:INFO:         statsmodels: 0.14.5
2025-10-09 18:25:36,108:INFO:              sktime: 0.26.0
2025-10-09 18:25:36,108:INFO:               tbats: 1.1.3
2025-10-09 18:25:36,108:INFO:            pmdarima: 2.0.4
2025-10-09 18:25:36,108:INFO:              psutil: 7.1.0
2025-10-09 18:25:36,108:INFO:          markupsafe: 3.0.3
2025-10-09 18:25:36,108:INFO:             pickle5: Not installed
2025-10-09 18:25:36,108:INFO:         cloudpickle: 3.1.1
2025-10-09 18:25:36,108:INFO:         deprecation: 2.1.0
2025-10-09 18:25:36,108:INFO:              xxhash: 3.6.0
2025-10-09 18:25:36,108:INFO:           wurlitzer: Not installed
2025-10-09 18:25:36,108:INFO:PyCaret optional dependencies:
2025-10-09 18:25:36,124:INFO:                shap: Not installed
2025-10-09 18:25:36,124:INFO:           interpret: Not installed
2025-10-09 18:25:36,124:INFO:                umap: Not installed
2025-10-09 18:25:36,124:INFO:     ydata_profiling: Not installed
2025-10-09 18:25:36,124:INFO:  explainerdashboard: Not installed
2025-10-09 18:25:36,124:INFO:             autoviz: Not installed
2025-10-09 18:25:36,124:INFO:           fairlearn: Not installed
2025-10-09 18:25:36,124:INFO:          deepchecks: Not installed
2025-10-09 18:25:36,124:INFO:             xgboost: Not installed
2025-10-09 18:25:36,124:INFO:            catboost: Not installed
2025-10-09 18:25:36,124:INFO:              kmodes: Not installed
2025-10-09 18:25:36,125:INFO:             mlxtend: Not installed
2025-10-09 18:25:36,125:INFO:       statsforecast: Not installed
2025-10-09 18:25:36,125:INFO:        tune_sklearn: Not installed
2025-10-09 18:25:36,125:INFO:                 ray: Not installed
2025-10-09 18:25:36,125:INFO:            hyperopt: Not installed
2025-10-09 18:25:36,125:INFO:              optuna: Not installed
2025-10-09 18:25:36,125:INFO:               skopt: Not installed
2025-10-09 18:25:36,125:INFO:              mlflow: Not installed
2025-10-09 18:25:36,125:INFO:              gradio: Not installed
2025-10-09 18:25:36,125:INFO:             fastapi: Not installed
2025-10-09 18:25:36,125:INFO:             uvicorn: Not installed
2025-10-09 18:25:36,125:INFO:              m2cgen: Not installed
2025-10-09 18:25:36,125:INFO:           evidently: Not installed
2025-10-09 18:25:36,125:INFO:               fugue: Not installed
2025-10-09 18:25:36,125:INFO:           streamlit: Not installed
2025-10-09 18:25:36,125:INFO:             prophet: Not installed
2025-10-09 18:25:36,125:INFO:None
2025-10-09 18:25:36,125:INFO:Set up data.
2025-10-09 18:25:36,130:INFO:Set up folding strategy.
2025-10-09 18:25:36,130:INFO:Set up train/test split.
2025-10-09 18:25:36,135:INFO:Set up index.
2025-10-09 18:25:36,136:INFO:Assigning column types.
2025-10-09 18:25:36,138:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-09 18:25:36,183:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 18:25:36,187:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 18:25:36,226:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:25:36,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:25:36,273:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 18:25:36,274:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 18:25:36,305:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:25:36,305:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:25:36,306:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-09 18:25:36,352:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 18:25:36,381:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:25:36,381:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:25:36,430:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 18:25:36,462:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:25:36,463:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:25:36,463:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-09 18:25:36,543:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:25:36,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:25:36,620:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:25:36,620:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:25:36,623:INFO:Preparing preprocessing pipeline...
2025-10-09 18:25:36,624:INFO:Set up simple imputation.
2025-10-09 18:25:36,626:INFO:Set up encoding of ordinal features.
2025-10-09 18:25:36,627:INFO:Set up encoding of categorical features.
2025-10-09 18:25:36,627:INFO:Set up feature normalization.
2025-10-09 18:25:36,736:INFO:Finished creating preprocessing pipeline.
2025-10-09 18:25:36,761:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jjqs_\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-10-09 18:25:36,761:INFO:Creating final display dataframe.
2025-10-09 18:25:36,999:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type            Binary
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 4
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              3d84
2025-10-09 18:25:37,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:25:37,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:25:37,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:25:37,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 18:25:37,175:INFO:setup() successfully completed in 1.11s...............
2025-10-09 18:25:40,905:INFO:Initializing compare_models()
2025-10-09 18:25:40,905:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-09 18:25:40,905:INFO:Checking exceptions
2025-10-09 18:25:40,910:INFO:Preparing display monitor
2025-10-09 18:25:40,940:INFO:Initializing Logistic Regression
2025-10-09 18:25:40,940:INFO:Total runtime is 0.0 minutes
2025-10-09 18:25:40,947:INFO:SubProcess create_model() called ==================================
2025-10-09 18:25:40,948:INFO:Initializing create_model()
2025-10-09 18:25:40,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E53429420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:25:40,948:INFO:Checking exceptions
2025-10-09 18:25:40,948:INFO:Importing libraries
2025-10-09 18:25:40,948:INFO:Copying training dataset
2025-10-09 18:25:40,954:INFO:Defining folds
2025-10-09 18:25:40,954:INFO:Declaring metric variables
2025-10-09 18:25:40,960:INFO:Importing untrained model
2025-10-09 18:25:40,966:INFO:Logistic Regression Imported successfully
2025-10-09 18:25:40,979:INFO:Starting cross validation
2025-10-09 18:25:40,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:25:47,690:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:47,709:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:47,714:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:47,738:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:47,749:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:47,771:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:47,809:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:47,849:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:47,861:INFO:Calculating mean and std
2025-10-09 18:25:47,863:INFO:Creating metrics dataframe
2025-10-09 18:25:47,867:INFO:Uploading results into container
2025-10-09 18:25:47,868:INFO:Uploading model into container now
2025-10-09 18:25:47,869:INFO:_master_model_container: 1
2025-10-09 18:25:47,869:INFO:_display_container: 2
2025-10-09 18:25:47,869:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 18:25:47,869:INFO:create_model() successfully completed......................................
2025-10-09 18:25:47,954:INFO:SubProcess create_model() end ==================================
2025-10-09 18:25:47,954:INFO:Creating metrics dataframe
2025-10-09 18:25:47,961:INFO:Initializing K Neighbors Classifier
2025-10-09 18:25:47,961:INFO:Total runtime is 0.11701245705286661 minutes
2025-10-09 18:25:47,965:INFO:SubProcess create_model() called ==================================
2025-10-09 18:25:47,966:INFO:Initializing create_model()
2025-10-09 18:25:47,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E53429420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:25:47,966:INFO:Checking exceptions
2025-10-09 18:25:47,966:INFO:Importing libraries
2025-10-09 18:25:47,966:INFO:Copying training dataset
2025-10-09 18:25:47,972:INFO:Defining folds
2025-10-09 18:25:47,972:INFO:Declaring metric variables
2025-10-09 18:25:47,978:INFO:Importing untrained model
2025-10-09 18:25:47,981:INFO:K Neighbors Classifier Imported successfully
2025-10-09 18:25:47,991:INFO:Starting cross validation
2025-10-09 18:25:47,993:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:25:48,281:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:48,284:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:48,308:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:48,309:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:48,310:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:51,249:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:51,257:INFO:Calculating mean and std
2025-10-09 18:25:51,259:INFO:Creating metrics dataframe
2025-10-09 18:25:51,262:INFO:Uploading results into container
2025-10-09 18:25:51,263:INFO:Uploading model into container now
2025-10-09 18:25:51,264:INFO:_master_model_container: 2
2025-10-09 18:25:51,265:INFO:_display_container: 2
2025-10-09 18:25:51,265:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 18:25:51,265:INFO:create_model() successfully completed......................................
2025-10-09 18:25:51,345:INFO:SubProcess create_model() end ==================================
2025-10-09 18:25:51,345:INFO:Creating metrics dataframe
2025-10-09 18:25:51,352:INFO:Initializing Naive Bayes
2025-10-09 18:25:51,352:INFO:Total runtime is 0.17351768016815186 minutes
2025-10-09 18:25:51,355:INFO:SubProcess create_model() called ==================================
2025-10-09 18:25:51,356:INFO:Initializing create_model()
2025-10-09 18:25:51,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E53429420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:25:51,356:INFO:Checking exceptions
2025-10-09 18:25:51,356:INFO:Importing libraries
2025-10-09 18:25:51,356:INFO:Copying training dataset
2025-10-09 18:25:51,360:INFO:Defining folds
2025-10-09 18:25:51,360:INFO:Declaring metric variables
2025-10-09 18:25:51,366:INFO:Importing untrained model
2025-10-09 18:25:51,372:INFO:Naive Bayes Imported successfully
2025-10-09 18:25:51,379:INFO:Starting cross validation
2025-10-09 18:25:51,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:25:51,567:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:51,576:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:51,601:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:51,602:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:51,619:INFO:Calculating mean and std
2025-10-09 18:25:51,621:INFO:Creating metrics dataframe
2025-10-09 18:25:51,622:INFO:Uploading results into container
2025-10-09 18:25:51,623:INFO:Uploading model into container now
2025-10-09 18:25:51,623:INFO:_master_model_container: 3
2025-10-09 18:25:51,624:INFO:_display_container: 2
2025-10-09 18:25:51,624:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 18:25:51,625:INFO:create_model() successfully completed......................................
2025-10-09 18:25:51,696:INFO:SubProcess create_model() end ==================================
2025-10-09 18:25:51,696:INFO:Creating metrics dataframe
2025-10-09 18:25:51,703:INFO:Initializing Decision Tree Classifier
2025-10-09 18:25:51,703:INFO:Total runtime is 0.17936865091323853 minutes
2025-10-09 18:25:51,707:INFO:SubProcess create_model() called ==================================
2025-10-09 18:25:51,707:INFO:Initializing create_model()
2025-10-09 18:25:51,707:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E53429420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:25:51,707:INFO:Checking exceptions
2025-10-09 18:25:51,707:INFO:Importing libraries
2025-10-09 18:25:51,707:INFO:Copying training dataset
2025-10-09 18:25:51,711:INFO:Defining folds
2025-10-09 18:25:51,712:INFO:Declaring metric variables
2025-10-09 18:25:51,716:INFO:Importing untrained model
2025-10-09 18:25:51,720:INFO:Decision Tree Classifier Imported successfully
2025-10-09 18:25:51,728:INFO:Starting cross validation
2025-10-09 18:25:51,731:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:25:51,938:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:51,962:INFO:Calculating mean and std
2025-10-09 18:25:51,964:INFO:Creating metrics dataframe
2025-10-09 18:25:51,967:INFO:Uploading results into container
2025-10-09 18:25:51,967:INFO:Uploading model into container now
2025-10-09 18:25:51,968:INFO:_master_model_container: 4
2025-10-09 18:25:51,968:INFO:_display_container: 2
2025-10-09 18:25:51,968:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 18:25:51,968:INFO:create_model() successfully completed......................................
2025-10-09 18:25:52,040:INFO:SubProcess create_model() end ==================================
2025-10-09 18:25:52,040:INFO:Creating metrics dataframe
2025-10-09 18:25:52,047:INFO:Initializing SVM - Linear Kernel
2025-10-09 18:25:52,047:INFO:Total runtime is 0.1851170857747396 minutes
2025-10-09 18:25:52,051:INFO:SubProcess create_model() called ==================================
2025-10-09 18:25:52,051:INFO:Initializing create_model()
2025-10-09 18:25:52,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E53429420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:25:52,051:INFO:Checking exceptions
2025-10-09 18:25:52,051:INFO:Importing libraries
2025-10-09 18:25:52,051:INFO:Copying training dataset
2025-10-09 18:25:52,055:INFO:Defining folds
2025-10-09 18:25:52,055:INFO:Declaring metric variables
2025-10-09 18:25:52,059:INFO:Importing untrained model
2025-10-09 18:25:52,063:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 18:25:52,073:INFO:Starting cross validation
2025-10-09 18:25:52,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:25:52,273:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:52,292:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:52,319:INFO:Calculating mean and std
2025-10-09 18:25:52,319:INFO:Creating metrics dataframe
2025-10-09 18:25:52,322:INFO:Uploading results into container
2025-10-09 18:25:52,322:INFO:Uploading model into container now
2025-10-09 18:25:52,324:INFO:_master_model_container: 5
2025-10-09 18:25:52,324:INFO:_display_container: 2
2025-10-09 18:25:52,324:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 18:25:52,325:INFO:create_model() successfully completed......................................
2025-10-09 18:25:52,399:INFO:SubProcess create_model() end ==================================
2025-10-09 18:25:52,399:INFO:Creating metrics dataframe
2025-10-09 18:25:52,406:INFO:Initializing Ridge Classifier
2025-10-09 18:25:52,406:INFO:Total runtime is 0.19109949668248497 minutes
2025-10-09 18:25:52,411:INFO:SubProcess create_model() called ==================================
2025-10-09 18:25:52,412:INFO:Initializing create_model()
2025-10-09 18:25:52,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E53429420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:25:52,412:INFO:Checking exceptions
2025-10-09 18:25:52,412:INFO:Importing libraries
2025-10-09 18:25:52,412:INFO:Copying training dataset
2025-10-09 18:25:52,415:INFO:Defining folds
2025-10-09 18:25:52,415:INFO:Declaring metric variables
2025-10-09 18:25:52,419:INFO:Importing untrained model
2025-10-09 18:25:52,424:INFO:Ridge Classifier Imported successfully
2025-10-09 18:25:52,434:INFO:Starting cross validation
2025-10-09 18:25:52,436:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:25:52,647:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:52,667:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:52,672:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:52,681:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:52,683:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:52,683:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:52,689:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:52,690:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:52,711:INFO:Calculating mean and std
2025-10-09 18:25:52,712:INFO:Creating metrics dataframe
2025-10-09 18:25:52,714:INFO:Uploading results into container
2025-10-09 18:25:52,715:INFO:Uploading model into container now
2025-10-09 18:25:52,716:INFO:_master_model_container: 6
2025-10-09 18:25:52,716:INFO:_display_container: 2
2025-10-09 18:25:52,716:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 18:25:52,716:INFO:create_model() successfully completed......................................
2025-10-09 18:25:52,785:INFO:SubProcess create_model() end ==================================
2025-10-09 18:25:52,785:INFO:Creating metrics dataframe
2025-10-09 18:25:52,795:INFO:Initializing Random Forest Classifier
2025-10-09 18:25:52,795:INFO:Total runtime is 0.19757458766301475 minutes
2025-10-09 18:25:52,799:INFO:SubProcess create_model() called ==================================
2025-10-09 18:25:52,799:INFO:Initializing create_model()
2025-10-09 18:25:52,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E53429420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:25:52,799:INFO:Checking exceptions
2025-10-09 18:25:52,799:INFO:Importing libraries
2025-10-09 18:25:52,799:INFO:Copying training dataset
2025-10-09 18:25:52,803:INFO:Defining folds
2025-10-09 18:25:52,803:INFO:Declaring metric variables
2025-10-09 18:25:52,807:INFO:Importing untrained model
2025-10-09 18:25:52,810:INFO:Random Forest Classifier Imported successfully
2025-10-09 18:25:52,818:INFO:Starting cross validation
2025-10-09 18:25:52,821:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:25:53,382:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:53,383:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:53,384:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:53,385:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:53,386:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:53,399:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:53,427:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:53,505:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:53,513:INFO:Calculating mean and std
2025-10-09 18:25:53,515:INFO:Creating metrics dataframe
2025-10-09 18:25:53,516:INFO:Uploading results into container
2025-10-09 18:25:53,517:INFO:Uploading model into container now
2025-10-09 18:25:53,518:INFO:_master_model_container: 7
2025-10-09 18:25:53,518:INFO:_display_container: 2
2025-10-09 18:25:53,518:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-09 18:25:53,518:INFO:create_model() successfully completed......................................
2025-10-09 18:25:53,586:INFO:SubProcess create_model() end ==================================
2025-10-09 18:25:53,586:INFO:Creating metrics dataframe
2025-10-09 18:25:53,595:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 18:25:53,595:INFO:Total runtime is 0.21091466347376508 minutes
2025-10-09 18:25:53,600:INFO:SubProcess create_model() called ==================================
2025-10-09 18:25:53,600:INFO:Initializing create_model()
2025-10-09 18:25:53,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E53429420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:25:53,601:INFO:Checking exceptions
2025-10-09 18:25:53,601:INFO:Importing libraries
2025-10-09 18:25:53,601:INFO:Copying training dataset
2025-10-09 18:25:53,606:INFO:Defining folds
2025-10-09 18:25:53,606:INFO:Declaring metric variables
2025-10-09 18:25:53,611:INFO:Importing untrained model
2025-10-09 18:25:53,614:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 18:25:53,625:INFO:Starting cross validation
2025-10-09 18:25:53,627:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:25:53,752:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:25:53,756:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:25:53,765:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:25:53,769:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:25:53,774:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:25:53,776:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:25:53,777:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:25:53,785:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:25:53,785:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:25:53,842:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:53,849:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:53,871:INFO:Calculating mean and std
2025-10-09 18:25:53,872:INFO:Creating metrics dataframe
2025-10-09 18:25:53,875:INFO:Uploading results into container
2025-10-09 18:25:53,876:INFO:Uploading model into container now
2025-10-09 18:25:53,876:INFO:_master_model_container: 8
2025-10-09 18:25:53,877:INFO:_display_container: 2
2025-10-09 18:25:53,877:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 18:25:53,877:INFO:create_model() successfully completed......................................
2025-10-09 18:25:53,948:INFO:SubProcess create_model() end ==================================
2025-10-09 18:25:53,948:INFO:Creating metrics dataframe
2025-10-09 18:25:53,958:INFO:Initializing Ada Boost Classifier
2025-10-09 18:25:53,958:INFO:Total runtime is 0.21695637702941897 minutes
2025-10-09 18:25:53,961:INFO:SubProcess create_model() called ==================================
2025-10-09 18:25:53,962:INFO:Initializing create_model()
2025-10-09 18:25:53,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E53429420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:25:53,962:INFO:Checking exceptions
2025-10-09 18:25:53,962:INFO:Importing libraries
2025-10-09 18:25:53,963:INFO:Copying training dataset
2025-10-09 18:25:53,967:INFO:Defining folds
2025-10-09 18:25:53,967:INFO:Declaring metric variables
2025-10-09 18:25:53,971:INFO:Importing untrained model
2025-10-09 18:25:53,976:INFO:Ada Boost Classifier Imported successfully
2025-10-09 18:25:53,988:INFO:Starting cross validation
2025-10-09 18:25:53,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:25:54,110:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:25:54,117:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:25:54,121:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:25:54,121:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:25:54,126:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:25:54,126:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:25:54,133:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:25:54,134:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:25:54,136:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:25:54,156:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:25:54,330:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:54,364:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:54,369:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:54,379:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:54,391:INFO:Calculating mean and std
2025-10-09 18:25:54,392:INFO:Creating metrics dataframe
2025-10-09 18:25:54,395:INFO:Uploading results into container
2025-10-09 18:25:54,396:INFO:Uploading model into container now
2025-10-09 18:25:54,397:INFO:_master_model_container: 9
2025-10-09 18:25:54,397:INFO:_display_container: 2
2025-10-09 18:25:54,397:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-09 18:25:54,398:INFO:create_model() successfully completed......................................
2025-10-09 18:25:54,471:INFO:SubProcess create_model() end ==================================
2025-10-09 18:25:54,471:INFO:Creating metrics dataframe
2025-10-09 18:25:54,480:INFO:Initializing Gradient Boosting Classifier
2025-10-09 18:25:54,480:INFO:Total runtime is 0.22565331061681115 minutes
2025-10-09 18:25:54,483:INFO:SubProcess create_model() called ==================================
2025-10-09 18:25:54,484:INFO:Initializing create_model()
2025-10-09 18:25:54,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E53429420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:25:54,484:INFO:Checking exceptions
2025-10-09 18:25:54,484:INFO:Importing libraries
2025-10-09 18:25:54,484:INFO:Copying training dataset
2025-10-09 18:25:54,488:INFO:Defining folds
2025-10-09 18:25:54,488:INFO:Declaring metric variables
2025-10-09 18:25:54,491:INFO:Importing untrained model
2025-10-09 18:25:54,495:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 18:25:54,505:INFO:Starting cross validation
2025-10-09 18:25:54,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:25:54,886:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:54,898:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:54,922:INFO:Calculating mean and std
2025-10-09 18:25:54,923:INFO:Creating metrics dataframe
2025-10-09 18:25:54,927:INFO:Uploading results into container
2025-10-09 18:25:54,927:INFO:Uploading model into container now
2025-10-09 18:25:54,928:INFO:_master_model_container: 10
2025-10-09 18:25:54,928:INFO:_display_container: 2
2025-10-09 18:25:54,929:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 18:25:54,929:INFO:create_model() successfully completed......................................
2025-10-09 18:25:55,001:INFO:SubProcess create_model() end ==================================
2025-10-09 18:25:55,001:INFO:Creating metrics dataframe
2025-10-09 18:25:55,010:INFO:Initializing Linear Discriminant Analysis
2025-10-09 18:25:55,010:INFO:Total runtime is 0.2344977458318075 minutes
2025-10-09 18:25:55,015:INFO:SubProcess create_model() called ==================================
2025-10-09 18:25:55,015:INFO:Initializing create_model()
2025-10-09 18:25:55,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E53429420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:25:55,015:INFO:Checking exceptions
2025-10-09 18:25:55,015:INFO:Importing libraries
2025-10-09 18:25:55,015:INFO:Copying training dataset
2025-10-09 18:25:55,021:INFO:Defining folds
2025-10-09 18:25:55,021:INFO:Declaring metric variables
2025-10-09 18:25:55,023:INFO:Importing untrained model
2025-10-09 18:25:55,027:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 18:25:55,038:INFO:Starting cross validation
2025-10-09 18:25:55,040:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:25:55,236:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:55,237:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:55,245:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:55,257:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:55,258:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:55,266:INFO:Calculating mean and std
2025-10-09 18:25:55,267:INFO:Creating metrics dataframe
2025-10-09 18:25:55,270:INFO:Uploading results into container
2025-10-09 18:25:55,270:INFO:Uploading model into container now
2025-10-09 18:25:55,271:INFO:_master_model_container: 11
2025-10-09 18:25:55,271:INFO:_display_container: 2
2025-10-09 18:25:55,271:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 18:25:55,271:INFO:create_model() successfully completed......................................
2025-10-09 18:25:55,343:INFO:SubProcess create_model() end ==================================
2025-10-09 18:25:55,343:INFO:Creating metrics dataframe
2025-10-09 18:25:55,354:INFO:Initializing Extra Trees Classifier
2025-10-09 18:25:55,354:INFO:Total runtime is 0.2402267138163249 minutes
2025-10-09 18:25:55,357:INFO:SubProcess create_model() called ==================================
2025-10-09 18:25:55,357:INFO:Initializing create_model()
2025-10-09 18:25:55,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E53429420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:25:55,359:INFO:Checking exceptions
2025-10-09 18:25:55,359:INFO:Importing libraries
2025-10-09 18:25:55,359:INFO:Copying training dataset
2025-10-09 18:25:55,363:INFO:Defining folds
2025-10-09 18:25:55,363:INFO:Declaring metric variables
2025-10-09 18:25:55,367:INFO:Importing untrained model
2025-10-09 18:25:55,371:INFO:Extra Trees Classifier Imported successfully
2025-10-09 18:25:55,382:INFO:Starting cross validation
2025-10-09 18:25:55,384:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:25:55,890:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:55,902:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:55,930:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:55,952:INFO:Calculating mean and std
2025-10-09 18:25:55,952:INFO:Creating metrics dataframe
2025-10-09 18:25:55,955:INFO:Uploading results into container
2025-10-09 18:25:55,956:INFO:Uploading model into container now
2025-10-09 18:25:55,956:INFO:_master_model_container: 12
2025-10-09 18:25:55,957:INFO:_display_container: 2
2025-10-09 18:25:55,957:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-09 18:25:55,958:INFO:create_model() successfully completed......................................
2025-10-09 18:25:56,029:INFO:SubProcess create_model() end ==================================
2025-10-09 18:25:56,029:INFO:Creating metrics dataframe
2025-10-09 18:25:56,039:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 18:25:56,040:INFO:Total runtime is 0.2516545653343201 minutes
2025-10-09 18:25:56,043:INFO:SubProcess create_model() called ==================================
2025-10-09 18:25:56,044:INFO:Initializing create_model()
2025-10-09 18:25:56,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E53429420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:25:56,044:INFO:Checking exceptions
2025-10-09 18:25:56,044:INFO:Importing libraries
2025-10-09 18:25:56,044:INFO:Copying training dataset
2025-10-09 18:25:56,049:INFO:Defining folds
2025-10-09 18:25:56,049:INFO:Declaring metric variables
2025-10-09 18:25:56,052:INFO:Importing untrained model
2025-10-09 18:25:56,056:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 18:25:56,065:INFO:Starting cross validation
2025-10-09 18:25:56,068:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:25:56,403:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:56,409:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:56,412:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:56,472:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:56,517:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:56,520:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:56,531:INFO:Calculating mean and std
2025-10-09 18:25:56,532:INFO:Creating metrics dataframe
2025-10-09 18:25:56,535:INFO:Uploading results into container
2025-10-09 18:25:56,536:INFO:Uploading model into container now
2025-10-09 18:25:56,536:INFO:_master_model_container: 13
2025-10-09 18:25:56,537:INFO:_display_container: 2
2025-10-09 18:25:56,539:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 18:25:56,539:INFO:create_model() successfully completed......................................
2025-10-09 18:25:56,641:INFO:SubProcess create_model() end ==================================
2025-10-09 18:25:56,641:INFO:Creating metrics dataframe
2025-10-09 18:25:56,655:INFO:Initializing Dummy Classifier
2025-10-09 18:25:56,655:INFO:Total runtime is 0.26190275351206466 minutes
2025-10-09 18:25:56,661:INFO:SubProcess create_model() called ==================================
2025-10-09 18:25:56,661:INFO:Initializing create_model()
2025-10-09 18:25:56,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E53429420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:25:56,661:INFO:Checking exceptions
2025-10-09 18:25:56,661:INFO:Importing libraries
2025-10-09 18:25:56,661:INFO:Copying training dataset
2025-10-09 18:25:56,665:INFO:Defining folds
2025-10-09 18:25:56,665:INFO:Declaring metric variables
2025-10-09 18:25:56,668:INFO:Importing untrained model
2025-10-09 18:25:56,672:INFO:Dummy Classifier Imported successfully
2025-10-09 18:25:56,683:INFO:Starting cross validation
2025-10-09 18:25:56,685:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:25:56,863:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:56,866:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:56,872:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:56,876:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:56,877:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:56,880:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:56,883:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:56,887:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:56,894:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:56,895:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:25:56,908:INFO:Calculating mean and std
2025-10-09 18:25:56,909:INFO:Creating metrics dataframe
2025-10-09 18:25:56,911:INFO:Uploading results into container
2025-10-09 18:25:56,912:INFO:Uploading model into container now
2025-10-09 18:25:56,913:INFO:_master_model_container: 14
2025-10-09 18:25:56,913:INFO:_display_container: 2
2025-10-09 18:25:56,914:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 18:25:56,914:INFO:create_model() successfully completed......................................
2025-10-09 18:25:56,984:INFO:SubProcess create_model() end ==================================
2025-10-09 18:25:56,984:INFO:Creating metrics dataframe
2025-10-09 18:25:56,996:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-10-09 18:25:57,005:INFO:Initializing create_model()
2025-10-09 18:25:57,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:25:57,005:INFO:Checking exceptions
2025-10-09 18:25:57,006:INFO:Importing libraries
2025-10-09 18:25:57,006:INFO:Copying training dataset
2025-10-09 18:25:57,011:INFO:Defining folds
2025-10-09 18:25:57,011:INFO:Declaring metric variables
2025-10-09 18:25:57,011:INFO:Importing untrained model
2025-10-09 18:25:57,011:INFO:Declaring custom model
2025-10-09 18:25:57,011:INFO:Dummy Classifier Imported successfully
2025-10-09 18:25:57,012:INFO:Cross validation set to False
2025-10-09 18:25:57,013:INFO:Fitting Model
2025-10-09 18:25:57,062:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 18:25:57,062:INFO:create_model() successfully completed......................................
2025-10-09 18:25:57,158:INFO:_master_model_container: 14
2025-10-09 18:25:57,158:INFO:_display_container: 2
2025-10-09 18:25:57,158:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 18:25:57,158:INFO:compare_models() successfully completed......................................
2025-10-09 18:27:54,428:INFO:Initializing compare_models()
2025-10-09 18:27:54,429:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-10-09 18:27:54,429:INFO:Checking exceptions
2025-10-09 18:27:54,432:INFO:Preparing display monitor
2025-10-09 18:27:54,463:INFO:Initializing Logistic Regression
2025-10-09 18:27:54,463:INFO:Total runtime is 0.0 minutes
2025-10-09 18:27:54,468:INFO:SubProcess create_model() called ==================================
2025-10-09 18:27:54,468:INFO:Initializing create_model()
2025-10-09 18:27:54,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E2051AAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:27:54,469:INFO:Checking exceptions
2025-10-09 18:27:54,469:INFO:Importing libraries
2025-10-09 18:27:54,469:INFO:Copying training dataset
2025-10-09 18:27:54,474:INFO:Defining folds
2025-10-09 18:27:54,474:INFO:Declaring metric variables
2025-10-09 18:27:54,479:INFO:Importing untrained model
2025-10-09 18:27:54,485:INFO:Logistic Regression Imported successfully
2025-10-09 18:27:54,494:INFO:Starting cross validation
2025-10-09 18:27:54,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:27:54,748:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:54,749:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:54,761:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:54,762:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:54,765:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:54,779:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:54,785:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:54,796:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:54,826:INFO:Calculating mean and std
2025-10-09 18:27:54,827:INFO:Creating metrics dataframe
2025-10-09 18:27:54,829:INFO:Uploading results into container
2025-10-09 18:27:54,829:INFO:Uploading model into container now
2025-10-09 18:27:54,829:INFO:_master_model_container: 15
2025-10-09 18:27:54,829:INFO:_display_container: 3
2025-10-09 18:27:54,830:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 18:27:54,830:INFO:create_model() successfully completed......................................
2025-10-09 18:27:54,904:INFO:SubProcess create_model() end ==================================
2025-10-09 18:27:54,904:INFO:Creating metrics dataframe
2025-10-09 18:27:54,910:INFO:Initializing K Neighbors Classifier
2025-10-09 18:27:54,911:INFO:Total runtime is 0.007457872231801351 minutes
2025-10-09 18:27:54,914:INFO:SubProcess create_model() called ==================================
2025-10-09 18:27:54,914:INFO:Initializing create_model()
2025-10-09 18:27:54,914:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E2051AAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:27:54,915:INFO:Checking exceptions
2025-10-09 18:27:54,915:INFO:Importing libraries
2025-10-09 18:27:54,915:INFO:Copying training dataset
2025-10-09 18:27:54,920:INFO:Defining folds
2025-10-09 18:27:54,920:INFO:Declaring metric variables
2025-10-09 18:27:54,923:INFO:Importing untrained model
2025-10-09 18:27:54,927:INFO:K Neighbors Classifier Imported successfully
2025-10-09 18:27:54,935:INFO:Starting cross validation
2025-10-09 18:27:54,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:27:55,221:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:55,240:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:55,241:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:55,242:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:55,244:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:55,256:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:55,272:INFO:Calculating mean and std
2025-10-09 18:27:55,273:INFO:Creating metrics dataframe
2025-10-09 18:27:55,274:INFO:Uploading results into container
2025-10-09 18:27:55,274:INFO:Uploading model into container now
2025-10-09 18:27:55,275:INFO:_master_model_container: 16
2025-10-09 18:27:55,275:INFO:_display_container: 3
2025-10-09 18:27:55,275:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 18:27:55,275:INFO:create_model() successfully completed......................................
2025-10-09 18:27:55,357:INFO:SubProcess create_model() end ==================================
2025-10-09 18:27:55,357:INFO:Creating metrics dataframe
2025-10-09 18:27:55,363:INFO:Initializing Naive Bayes
2025-10-09 18:27:55,363:INFO:Total runtime is 0.01499768892923991 minutes
2025-10-09 18:27:55,367:INFO:SubProcess create_model() called ==================================
2025-10-09 18:27:55,367:INFO:Initializing create_model()
2025-10-09 18:27:55,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E2051AAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:27:55,368:INFO:Checking exceptions
2025-10-09 18:27:55,368:INFO:Importing libraries
2025-10-09 18:27:55,368:INFO:Copying training dataset
2025-10-09 18:27:55,372:INFO:Defining folds
2025-10-09 18:27:55,372:INFO:Declaring metric variables
2025-10-09 18:27:55,376:INFO:Importing untrained model
2025-10-09 18:27:55,381:INFO:Naive Bayes Imported successfully
2025-10-09 18:27:55,391:INFO:Starting cross validation
2025-10-09 18:27:55,393:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:27:55,615:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:55,617:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:55,635:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:55,637:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:55,645:INFO:Calculating mean and std
2025-10-09 18:27:55,646:INFO:Creating metrics dataframe
2025-10-09 18:27:55,648:INFO:Uploading results into container
2025-10-09 18:27:55,649:INFO:Uploading model into container now
2025-10-09 18:27:55,650:INFO:_master_model_container: 17
2025-10-09 18:27:55,650:INFO:_display_container: 3
2025-10-09 18:27:55,650:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 18:27:55,651:INFO:create_model() successfully completed......................................
2025-10-09 18:27:55,728:INFO:SubProcess create_model() end ==================================
2025-10-09 18:27:55,729:INFO:Creating metrics dataframe
2025-10-09 18:27:55,736:INFO:Initializing Decision Tree Classifier
2025-10-09 18:27:55,736:INFO:Total runtime is 0.021217437585194905 minutes
2025-10-09 18:27:55,739:INFO:SubProcess create_model() called ==================================
2025-10-09 18:27:55,739:INFO:Initializing create_model()
2025-10-09 18:27:55,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E2051AAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:27:55,741:INFO:Checking exceptions
2025-10-09 18:27:55,741:INFO:Importing libraries
2025-10-09 18:27:55,741:INFO:Copying training dataset
2025-10-09 18:27:55,745:INFO:Defining folds
2025-10-09 18:27:55,746:INFO:Declaring metric variables
2025-10-09 18:27:55,749:INFO:Importing untrained model
2025-10-09 18:27:55,752:INFO:Decision Tree Classifier Imported successfully
2025-10-09 18:27:55,763:INFO:Starting cross validation
2025-10-09 18:27:55,766:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:27:55,984:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:56,003:INFO:Calculating mean and std
2025-10-09 18:27:56,004:INFO:Creating metrics dataframe
2025-10-09 18:27:56,006:INFO:Uploading results into container
2025-10-09 18:27:56,007:INFO:Uploading model into container now
2025-10-09 18:27:56,007:INFO:_master_model_container: 18
2025-10-09 18:27:56,007:INFO:_display_container: 3
2025-10-09 18:27:56,008:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 18:27:56,008:INFO:create_model() successfully completed......................................
2025-10-09 18:27:56,083:INFO:SubProcess create_model() end ==================================
2025-10-09 18:27:56,083:INFO:Creating metrics dataframe
2025-10-09 18:27:56,090:INFO:Initializing SVM - Linear Kernel
2025-10-09 18:27:56,090:INFO:Total runtime is 0.027110834916432697 minutes
2025-10-09 18:27:56,094:INFO:SubProcess create_model() called ==================================
2025-10-09 18:27:56,095:INFO:Initializing create_model()
2025-10-09 18:27:56,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E2051AAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:27:56,095:INFO:Checking exceptions
2025-10-09 18:27:56,095:INFO:Importing libraries
2025-10-09 18:27:56,095:INFO:Copying training dataset
2025-10-09 18:27:56,099:INFO:Defining folds
2025-10-09 18:27:56,100:INFO:Declaring metric variables
2025-10-09 18:27:56,104:INFO:Importing untrained model
2025-10-09 18:27:56,109:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 18:27:56,118:INFO:Starting cross validation
2025-10-09 18:27:56,120:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:27:56,319:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:56,324:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:56,362:INFO:Calculating mean and std
2025-10-09 18:27:56,364:INFO:Creating metrics dataframe
2025-10-09 18:27:56,366:INFO:Uploading results into container
2025-10-09 18:27:56,367:INFO:Uploading model into container now
2025-10-09 18:27:56,368:INFO:_master_model_container: 19
2025-10-09 18:27:56,368:INFO:_display_container: 3
2025-10-09 18:27:56,369:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 18:27:56,369:INFO:create_model() successfully completed......................................
2025-10-09 18:27:56,444:INFO:SubProcess create_model() end ==================================
2025-10-09 18:27:56,444:INFO:Creating metrics dataframe
2025-10-09 18:27:56,452:INFO:Initializing Ridge Classifier
2025-10-09 18:27:56,452:INFO:Total runtime is 0.03314741849899292 minutes
2025-10-09 18:27:56,455:INFO:SubProcess create_model() called ==================================
2025-10-09 18:27:56,455:INFO:Initializing create_model()
2025-10-09 18:27:56,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E2051AAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:27:56,455:INFO:Checking exceptions
2025-10-09 18:27:56,455:INFO:Importing libraries
2025-10-09 18:27:56,455:INFO:Copying training dataset
2025-10-09 18:27:56,460:INFO:Defining folds
2025-10-09 18:27:56,460:INFO:Declaring metric variables
2025-10-09 18:27:56,464:INFO:Importing untrained model
2025-10-09 18:27:56,468:INFO:Ridge Classifier Imported successfully
2025-10-09 18:27:56,478:INFO:Starting cross validation
2025-10-09 18:27:56,481:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:27:56,667:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:56,667:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:56,686:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:56,691:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:56,696:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:56,698:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:56,699:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:56,701:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:56,715:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:56,735:INFO:Calculating mean and std
2025-10-09 18:27:56,736:INFO:Creating metrics dataframe
2025-10-09 18:27:56,738:INFO:Uploading results into container
2025-10-09 18:27:56,739:INFO:Uploading model into container now
2025-10-09 18:27:56,740:INFO:_master_model_container: 20
2025-10-09 18:27:56,741:INFO:_display_container: 3
2025-10-09 18:27:56,741:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 18:27:56,741:INFO:create_model() successfully completed......................................
2025-10-09 18:27:56,819:INFO:SubProcess create_model() end ==================================
2025-10-09 18:27:56,819:INFO:Creating metrics dataframe
2025-10-09 18:27:56,826:INFO:Initializing Random Forest Classifier
2025-10-09 18:27:56,827:INFO:Total runtime is 0.03939609527587891 minutes
2025-10-09 18:27:56,831:INFO:SubProcess create_model() called ==================================
2025-10-09 18:27:56,831:INFO:Initializing create_model()
2025-10-09 18:27:56,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E2051AAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:27:56,831:INFO:Checking exceptions
2025-10-09 18:27:56,831:INFO:Importing libraries
2025-10-09 18:27:56,832:INFO:Copying training dataset
2025-10-09 18:27:56,835:INFO:Defining folds
2025-10-09 18:27:56,836:INFO:Declaring metric variables
2025-10-09 18:27:56,839:INFO:Importing untrained model
2025-10-09 18:27:56,843:INFO:Random Forest Classifier Imported successfully
2025-10-09 18:27:56,854:INFO:Starting cross validation
2025-10-09 18:27:56,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:27:57,435:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:57,438:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:57,478:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:58,905:INFO:Calculating mean and std
2025-10-09 18:27:58,906:INFO:Creating metrics dataframe
2025-10-09 18:27:58,909:INFO:Uploading results into container
2025-10-09 18:27:58,910:INFO:Uploading model into container now
2025-10-09 18:27:58,911:INFO:_master_model_container: 21
2025-10-09 18:27:58,911:INFO:_display_container: 3
2025-10-09 18:27:58,911:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-09 18:27:58,912:INFO:create_model() successfully completed......................................
2025-10-09 18:27:58,990:INFO:SubProcess create_model() end ==================================
2025-10-09 18:27:58,990:INFO:Creating metrics dataframe
2025-10-09 18:27:58,998:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 18:27:58,998:INFO:Total runtime is 0.07558019161224366 minutes
2025-10-09 18:27:59,003:INFO:SubProcess create_model() called ==================================
2025-10-09 18:27:59,003:INFO:Initializing create_model()
2025-10-09 18:27:59,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E2051AAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:27:59,003:INFO:Checking exceptions
2025-10-09 18:27:59,004:INFO:Importing libraries
2025-10-09 18:27:59,004:INFO:Copying training dataset
2025-10-09 18:27:59,008:INFO:Defining folds
2025-10-09 18:27:59,008:INFO:Declaring metric variables
2025-10-09 18:27:59,011:INFO:Importing untrained model
2025-10-09 18:27:59,017:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 18:27:59,028:INFO:Starting cross validation
2025-10-09 18:27:59,030:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:27:59,197:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:27:59,200:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:27:59,207:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:27:59,208:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:27:59,208:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:27:59,225:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:27:59,230:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:27:59,231:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:27:59,255:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 18:27:59,270:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:59,314:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:59,325:INFO:Calculating mean and std
2025-10-09 18:27:59,327:INFO:Creating metrics dataframe
2025-10-09 18:27:59,329:INFO:Uploading results into container
2025-10-09 18:27:59,330:INFO:Uploading model into container now
2025-10-09 18:27:59,331:INFO:_master_model_container: 22
2025-10-09 18:27:59,331:INFO:_display_container: 3
2025-10-09 18:27:59,331:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 18:27:59,331:INFO:create_model() successfully completed......................................
2025-10-09 18:27:59,408:INFO:SubProcess create_model() end ==================================
2025-10-09 18:27:59,408:INFO:Creating metrics dataframe
2025-10-09 18:27:59,418:INFO:Initializing Ada Boost Classifier
2025-10-09 18:27:59,418:INFO:Total runtime is 0.08257604042689007 minutes
2025-10-09 18:27:59,423:INFO:SubProcess create_model() called ==================================
2025-10-09 18:27:59,423:INFO:Initializing create_model()
2025-10-09 18:27:59,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E2051AAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:27:59,423:INFO:Checking exceptions
2025-10-09 18:27:59,423:INFO:Importing libraries
2025-10-09 18:27:59,423:INFO:Copying training dataset
2025-10-09 18:27:59,427:INFO:Defining folds
2025-10-09 18:27:59,427:INFO:Declaring metric variables
2025-10-09 18:27:59,430:INFO:Importing untrained model
2025-10-09 18:27:59,434:INFO:Ada Boost Classifier Imported successfully
2025-10-09 18:27:59,446:INFO:Starting cross validation
2025-10-09 18:27:59,449:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:27:59,581:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:27:59,584:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:27:59,590:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:27:59,592:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:27:59,592:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:27:59,596:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:27:59,597:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:27:59,600:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:27:59,603:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:27:59,605:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 18:27:59,801:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:59,817:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:59,825:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:59,835:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:27:59,857:INFO:Calculating mean and std
2025-10-09 18:27:59,859:INFO:Creating metrics dataframe
2025-10-09 18:27:59,861:INFO:Uploading results into container
2025-10-09 18:27:59,862:INFO:Uploading model into container now
2025-10-09 18:27:59,862:INFO:_master_model_container: 23
2025-10-09 18:27:59,862:INFO:_display_container: 3
2025-10-09 18:27:59,863:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-09 18:27:59,863:INFO:create_model() successfully completed......................................
2025-10-09 18:27:59,941:INFO:SubProcess create_model() end ==================================
2025-10-09 18:27:59,941:INFO:Creating metrics dataframe
2025-10-09 18:27:59,949:INFO:Initializing Gradient Boosting Classifier
2025-10-09 18:27:59,949:INFO:Total runtime is 0.09143489996592205 minutes
2025-10-09 18:27:59,953:INFO:SubProcess create_model() called ==================================
2025-10-09 18:27:59,955:INFO:Initializing create_model()
2025-10-09 18:27:59,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E2051AAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:27:59,955:INFO:Checking exceptions
2025-10-09 18:27:59,955:INFO:Importing libraries
2025-10-09 18:27:59,955:INFO:Copying training dataset
2025-10-09 18:27:59,959:INFO:Defining folds
2025-10-09 18:27:59,959:INFO:Declaring metric variables
2025-10-09 18:27:59,963:INFO:Importing untrained model
2025-10-09 18:27:59,968:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 18:27:59,979:INFO:Starting cross validation
2025-10-09 18:27:59,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:28:00,371:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:00,375:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:00,419:INFO:Calculating mean and std
2025-10-09 18:28:00,420:INFO:Creating metrics dataframe
2025-10-09 18:28:00,422:INFO:Uploading results into container
2025-10-09 18:28:00,423:INFO:Uploading model into container now
2025-10-09 18:28:00,423:INFO:_master_model_container: 24
2025-10-09 18:28:00,423:INFO:_display_container: 3
2025-10-09 18:28:00,423:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 18:28:00,424:INFO:create_model() successfully completed......................................
2025-10-09 18:28:00,500:INFO:SubProcess create_model() end ==================================
2025-10-09 18:28:00,500:INFO:Creating metrics dataframe
2025-10-09 18:28:00,509:INFO:Initializing Linear Discriminant Analysis
2025-10-09 18:28:00,509:INFO:Total runtime is 0.1007596492767334 minutes
2025-10-09 18:28:00,513:INFO:SubProcess create_model() called ==================================
2025-10-09 18:28:00,513:INFO:Initializing create_model()
2025-10-09 18:28:00,513:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E2051AAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:28:00,513:INFO:Checking exceptions
2025-10-09 18:28:00,514:INFO:Importing libraries
2025-10-09 18:28:00,514:INFO:Copying training dataset
2025-10-09 18:28:00,518:INFO:Defining folds
2025-10-09 18:28:00,518:INFO:Declaring metric variables
2025-10-09 18:28:00,520:INFO:Importing untrained model
2025-10-09 18:28:00,525:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 18:28:00,536:INFO:Starting cross validation
2025-10-09 18:28:00,539:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:28:00,729:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:00,741:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:00,744:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:00,747:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:00,748:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:00,760:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:00,776:INFO:Calculating mean and std
2025-10-09 18:28:00,777:INFO:Creating metrics dataframe
2025-10-09 18:28:00,779:INFO:Uploading results into container
2025-10-09 18:28:00,781:INFO:Uploading model into container now
2025-10-09 18:28:00,781:INFO:_master_model_container: 25
2025-10-09 18:28:00,782:INFO:_display_container: 3
2025-10-09 18:28:00,782:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 18:28:00,783:INFO:create_model() successfully completed......................................
2025-10-09 18:28:00,858:INFO:SubProcess create_model() end ==================================
2025-10-09 18:28:00,858:INFO:Creating metrics dataframe
2025-10-09 18:28:00,867:INFO:Initializing Extra Trees Classifier
2025-10-09 18:28:00,867:INFO:Total runtime is 0.10674049456914267 minutes
2025-10-09 18:28:00,870:INFO:SubProcess create_model() called ==================================
2025-10-09 18:28:00,870:INFO:Initializing create_model()
2025-10-09 18:28:00,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E2051AAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:28:00,870:INFO:Checking exceptions
2025-10-09 18:28:00,872:INFO:Importing libraries
2025-10-09 18:28:00,872:INFO:Copying training dataset
2025-10-09 18:28:00,875:INFO:Defining folds
2025-10-09 18:28:00,875:INFO:Declaring metric variables
2025-10-09 18:28:00,879:INFO:Importing untrained model
2025-10-09 18:28:00,883:INFO:Extra Trees Classifier Imported successfully
2025-10-09 18:28:00,894:INFO:Starting cross validation
2025-10-09 18:28:00,896:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:28:01,383:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:01,412:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:01,413:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:01,508:INFO:Calculating mean and std
2025-10-09 18:28:01,509:INFO:Creating metrics dataframe
2025-10-09 18:28:01,512:INFO:Uploading results into container
2025-10-09 18:28:01,512:INFO:Uploading model into container now
2025-10-09 18:28:01,513:INFO:_master_model_container: 26
2025-10-09 18:28:01,513:INFO:_display_container: 3
2025-10-09 18:28:01,514:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-09 18:28:01,514:INFO:create_model() successfully completed......................................
2025-10-09 18:28:01,591:INFO:SubProcess create_model() end ==================================
2025-10-09 18:28:01,592:INFO:Creating metrics dataframe
2025-10-09 18:28:01,603:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 18:28:01,603:INFO:Total runtime is 0.11899176041285198 minutes
2025-10-09 18:28:01,607:INFO:SubProcess create_model() called ==================================
2025-10-09 18:28:01,608:INFO:Initializing create_model()
2025-10-09 18:28:01,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E2051AAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:28:01,608:INFO:Checking exceptions
2025-10-09 18:28:01,608:INFO:Importing libraries
2025-10-09 18:28:01,608:INFO:Copying training dataset
2025-10-09 18:28:01,612:INFO:Defining folds
2025-10-09 18:28:01,612:INFO:Declaring metric variables
2025-10-09 18:28:01,615:INFO:Importing untrained model
2025-10-09 18:28:01,619:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 18:28:01,630:INFO:Starting cross validation
2025-10-09 18:28:01,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:28:01,985:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:01,997:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:02,017:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:02,096:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:02,132:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:02,134:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:02,147:INFO:Calculating mean and std
2025-10-09 18:28:02,148:INFO:Creating metrics dataframe
2025-10-09 18:28:02,151:INFO:Uploading results into container
2025-10-09 18:28:02,152:INFO:Uploading model into container now
2025-10-09 18:28:02,153:INFO:_master_model_container: 27
2025-10-09 18:28:02,154:INFO:_display_container: 3
2025-10-09 18:28:02,155:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 18:28:02,155:INFO:create_model() successfully completed......................................
2025-10-09 18:28:02,248:INFO:SubProcess create_model() end ==================================
2025-10-09 18:28:02,248:INFO:Creating metrics dataframe
2025-10-09 18:28:02,257:INFO:Initializing Dummy Classifier
2025-10-09 18:28:02,258:INFO:Total runtime is 0.12991573015848795 minutes
2025-10-09 18:28:02,262:INFO:SubProcess create_model() called ==================================
2025-10-09 18:28:02,263:INFO:Initializing create_model()
2025-10-09 18:28:02,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E2051AAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:28:02,263:INFO:Checking exceptions
2025-10-09 18:28:02,263:INFO:Importing libraries
2025-10-09 18:28:02,263:INFO:Copying training dataset
2025-10-09 18:28:02,267:INFO:Defining folds
2025-10-09 18:28:02,267:INFO:Declaring metric variables
2025-10-09 18:28:02,271:INFO:Importing untrained model
2025-10-09 18:28:02,276:INFO:Dummy Classifier Imported successfully
2025-10-09 18:28:02,291:INFO:Starting cross validation
2025-10-09 18:28:02,295:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:28:02,503:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:02,504:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:02,506:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:02,512:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:02,513:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:02,513:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:02,515:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:02,519:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:02,519:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:02,527:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:02,538:INFO:Calculating mean and std
2025-10-09 18:28:02,538:INFO:Creating metrics dataframe
2025-10-09 18:28:02,541:INFO:Uploading results into container
2025-10-09 18:28:02,542:INFO:Uploading model into container now
2025-10-09 18:28:02,543:INFO:_master_model_container: 28
2025-10-09 18:28:02,543:INFO:_display_container: 3
2025-10-09 18:28:02,543:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 18:28:02,543:INFO:create_model() successfully completed......................................
2025-10-09 18:28:02,621:INFO:SubProcess create_model() end ==================================
2025-10-09 18:28:02,621:INFO:Creating metrics dataframe
2025-10-09 18:28:02,633:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-10-09 18:28:02,643:INFO:Initializing create_model()
2025-10-09 18:28:02,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:28:02,644:INFO:Checking exceptions
2025-10-09 18:28:02,646:INFO:Importing libraries
2025-10-09 18:28:02,646:INFO:Copying training dataset
2025-10-09 18:28:02,650:INFO:Defining folds
2025-10-09 18:28:02,650:INFO:Declaring metric variables
2025-10-09 18:28:02,650:INFO:Importing untrained model
2025-10-09 18:28:02,650:INFO:Declaring custom model
2025-10-09 18:28:02,650:INFO:Dummy Classifier Imported successfully
2025-10-09 18:28:02,652:INFO:Cross validation set to False
2025-10-09 18:28:02,652:INFO:Fitting Model
2025-10-09 18:28:02,705:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 18:28:02,706:INFO:create_model() successfully completed......................................
2025-10-09 18:28:02,828:INFO:_master_model_container: 28
2025-10-09 18:28:02,828:INFO:_display_container: 3
2025-10-09 18:28:02,829:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 18:28:02,829:INFO:compare_models() successfully completed......................................
2025-10-09 18:28:07,493:INFO:Initializing create_model()
2025-10-09 18:28:07,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:28:07,493:INFO:Checking exceptions
2025-10-09 18:28:07,514:INFO:Importing libraries
2025-10-09 18:28:07,514:INFO:Copying training dataset
2025-10-09 18:28:07,522:INFO:Defining folds
2025-10-09 18:28:07,522:INFO:Declaring metric variables
2025-10-09 18:28:07,526:INFO:Importing untrained model
2025-10-09 18:28:07,532:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 18:28:07,542:INFO:Starting cross validation
2025-10-09 18:28:07,544:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:28:07,914:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:07,920:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:07,925:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:07,934:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:08,021:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:08,054:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:08,063:INFO:Calculating mean and std
2025-10-09 18:28:08,064:INFO:Creating metrics dataframe
2025-10-09 18:28:08,071:INFO:Finalizing model
2025-10-09 18:28:08,153:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-10-09 18:28:08,154:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000041 seconds.
2025-10-09 18:28:08,154:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-09 18:28:08,154:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-09 18:28:08,154:INFO:[LightGBM] [Info] Total Bins 117
2025-10-09 18:28:08,154:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-10-09 18:28:08,154:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-10-09 18:28:08,154:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-10-09 18:28:08,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:08,190:INFO:Uploading results into container
2025-10-09 18:28:08,191:INFO:Uploading model into container now
2025-10-09 18:28:08,205:INFO:_master_model_container: 29
2025-10-09 18:28:08,205:INFO:_display_container: 4
2025-10-09 18:28:08,207:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 18:28:08,207:INFO:create_model() successfully completed......................................
2025-10-09 18:28:13,769:INFO:Initializing tune_model()
2025-10-09 18:28:13,770:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>)
2025-10-09 18:28:13,770:INFO:Checking exceptions
2025-10-09 18:28:13,792:INFO:Copying training dataset
2025-10-09 18:28:13,796:INFO:Checking base model
2025-10-09 18:28:13,796:INFO:Base model : Light Gradient Boosting Machine
2025-10-09 18:28:13,803:INFO:Declaring metric variables
2025-10-09 18:28:13,808:INFO:Defining Hyperparameters
2025-10-09 18:28:13,907:INFO:Tuning with n_jobs=-1
2025-10-09 18:28:13,908:INFO:Initializing RandomizedSearchCV
2025-10-09 18:28:18,462:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2025-10-09 18:28:18,463:INFO:Hyperparameter search completed
2025-10-09 18:28:18,464:INFO:SubProcess create_model() called ==================================
2025-10-09 18:28:18,465:INFO:Initializing create_model()
2025-10-09 18:28:18,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023E5300A9E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 91, 'learning_rate': 1e-07, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2025-10-09 18:28:18,465:INFO:Checking exceptions
2025-10-09 18:28:18,466:INFO:Importing libraries
2025-10-09 18:28:18,466:INFO:Copying training dataset
2025-10-09 18:28:18,473:INFO:Defining folds
2025-10-09 18:28:18,473:INFO:Declaring metric variables
2025-10-09 18:28:18,478:INFO:Importing untrained model
2025-10-09 18:28:18,478:INFO:Declaring custom model
2025-10-09 18:28:18,484:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 18:28:18,494:INFO:Starting cross validation
2025-10-09 18:28:18,498:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:28:18,809:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:18,811:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:18,817:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:18,826:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:18,921:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:18,933:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:18,941:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:18,950:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:18,961:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:18,966:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:18,976:INFO:Calculating mean and std
2025-10-09 18:28:18,978:INFO:Creating metrics dataframe
2025-10-09 18:28:18,986:INFO:Finalizing model
2025-10-09 18:28:19,060:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-10-09 18:28:19,061:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-10-09 18:28:19,061:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-10-09 18:28:19,061:INFO:[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.
2025-10-09 18:28:19,061:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-10-09 18:28:19,061:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-10-09 18:28:19,061:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-10-09 18:28:19,062:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-10-09 18:28:19,062:INFO:[LightGBM] [Info] Total Bins 0
2025-10-09 18:28:19,062:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 0
2025-10-09 18:28:19,062:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-10-09 18:28:19,062:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-10-09 18:28:19,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,073:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,073:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,073:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,073:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,073:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,073:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,073:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,076:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,076:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,076:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,076:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,076:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,076:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 18:28:19,083:INFO:Uploading results into container
2025-10-09 18:28:19,084:INFO:Uploading model into container now
2025-10-09 18:28:19,085:INFO:_master_model_container: 30
2025-10-09 18:28:19,085:INFO:_display_container: 5
2025-10-09 18:28:19,086:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 18:28:19,086:INFO:create_model() successfully completed......................................
2025-10-09 18:28:19,185:INFO:SubProcess create_model() end ==================================
2025-10-09 18:28:19,185:INFO:choose_better activated
2025-10-09 18:28:19,189:INFO:SubProcess create_model() called ==================================
2025-10-09 18:28:19,189:INFO:Initializing create_model()
2025-10-09 18:28:19,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 18:28:19,190:INFO:Checking exceptions
2025-10-09 18:28:19,191:INFO:Importing libraries
2025-10-09 18:28:19,192:INFO:Copying training dataset
2025-10-09 18:28:19,195:INFO:Defining folds
2025-10-09 18:28:19,195:INFO:Declaring metric variables
2025-10-09 18:28:19,195:INFO:Importing untrained model
2025-10-09 18:28:19,195:INFO:Declaring custom model
2025-10-09 18:28:19,196:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 18:28:19,196:INFO:Starting cross validation
2025-10-09 18:28:19,197:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 18:28:19,552:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:19,578:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:19,630:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:19,687:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:19,705:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:19,741:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:19,763:INFO:Calculating mean and std
2025-10-09 18:28:19,764:INFO:Creating metrics dataframe
2025-10-09 18:28:19,766:INFO:Finalizing model
2025-10-09 18:28:19,833:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-10-09 18:28:19,833:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.
2025-10-09 18:28:19,833:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-09 18:28:19,833:INFO:[LightGBM] [Info] Total Bins 117
2025-10-09 18:28:19,833:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-10-09 18:28:19,833:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-10-09 18:28:19,833:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-10-09 18:28:19,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 18:28:19,865:INFO:Uploading results into container
2025-10-09 18:28:19,866:INFO:Uploading model into container now
2025-10-09 18:28:19,867:INFO:_master_model_container: 31
2025-10-09 18:28:19,867:INFO:_display_container: 6
2025-10-09 18:28:19,867:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 18:28:19,868:INFO:create_model() successfully completed......................................
2025-10-09 18:28:19,958:INFO:SubProcess create_model() end ==================================
2025-10-09 18:28:19,959:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7891
2025-10-09 18:28:19,960:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8291
2025-10-09 18:28:19,961:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-10-09 18:28:19,961:INFO:choose_better completed
2025-10-09 18:28:19,971:INFO:_master_model_container: 31
2025-10-09 18:28:19,972:INFO:_display_container: 5
2025-10-09 18:28:19,973:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 18:28:19,973:INFO:tune_model() successfully completed......................................
2025-10-09 18:28:23,994:INFO:Initializing evaluate_model()
2025-10-09 18:28:23,995:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-09 18:28:24,007:INFO:Initializing plot_model()
2025-10-09 18:28:24,008:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, system=True)
2025-10-09 18:28:24,008:INFO:Checking exceptions
2025-10-09 18:28:24,012:INFO:Preloading libraries
2025-10-09 18:28:24,016:INFO:Copying training dataset
2025-10-09 18:28:24,016:INFO:Plot type: pipeline
2025-10-09 18:28:24,238:INFO:Visual Rendered Successfully
2025-10-09 18:28:24,314:INFO:plot_model() successfully completed......................................
2025-10-09 18:28:28,355:INFO:Initializing predict_model()
2025-10-09 18:28:28,355:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E5300A8C0>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023E54BA8430>)
2025-10-09 18:28:28,355:INFO:Checking exceptions
2025-10-09 18:28:28,355:INFO:Preloading libraries
2025-10-09 18:28:28,490:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 18:28:49,868:INFO:Initializing save_model()
2025-10-09 18:28:49,868:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), model_name=modelo_precio_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jjqs_\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-09 18:28:49,868:INFO:Adding model into prep_pipe
2025-10-09 18:28:49,877:INFO:modelo_precio_final.pkl saved in current working directory
2025-10-09 18:28:49,914:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-10-09 18:28:50,222:INFO:save_model() successfully completed......................................
